# -*- coding: utf-8 -*-
"""
ğŸš€ CLISONIX INTELLIGENCE INTEGRATION RUNNER
===========================================
Runner pÃ«r integrimin e plotÃ« tÃ« moduleve tÃ« inteligjencÃ«s Clisonix

Ky modul pÃ«rfshin:
- Integrim i plotÃ« i tÃ« gjithÃ« moduleve
- Orkestrim i pipeline-ve AI/AGI
- Skanim dhe zbulim API
- Gjenerim dhe deploy i inteligjencÃ«s
- Monitorim dhe metrika real-time
"""

from __future__ import annotations
import asyncio
import json
import uuid
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Set, Tuple, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import logging
import argparse
import sys
from pathlib import Path

# Konfigurimi i logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('clisonix_integration.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

try:
    from enhanced_asi import get_enhanced_asi, IntelligenceType, IntelligenceUnit
    from cycle_engine import get_cycle_engine, CycleType, AlignmentPolicy
    from open_data_scalability import get_scalability_engine
    from ai_agi_pipeline import get_pipeline_builder, PipelineType
    INTEGRATIONS_AVAILABLE = True
except ImportError as e:
    logger.warning(f"Disa integrime nuk janÃ« tÃ« disponueshme: {e}")
    INTEGRATIONS_AVAILABLE = False

class IntegrationMode(Enum):
    """Modalitetet e integrimit"""
    FULL_INTEGRATION = "full_integration"        # Integrim i plotÃ«
    SCALABILITY_FOCUS = "scalability_focus"      # Fokus nÃ« skalabilitet
    INTELLIGENCE_FOCUS = "intelligence_focus"    # Fokus nÃ« inteligjencÃ«
    API_DISCOVERY = "api_discovery"              # Zbulim API
    PIPELINE_EXECUTION = "pipeline_execution"    # Ekzekutim pipeline
    MONITORING_MODE = "monitoring_mode"          # Modalitet monitorimi

@dataclass
class IntegrationConfig:
    """Konfigurimi i integrimit"""
    mode: IntegrationMode = IntegrationMode.FULL_INTEGRATION
    enable_api_scanning: bool = True
    enable_pipeline_execution: bool = True
    enable_real_time_monitoring: bool = True
    max_concurrent_operations: int = 5
    cycle_timeout: int = 300  # sekonda
    intelligence_batch_size: int = 10
    api_scan_interval: int = 3600  # sekonda
    output_directory: str = "./integration_output"
    log_level: str = "INFO"

@dataclass
class IntegrationMetrics:
    """Metrikat e integrimit"""
    start_time: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    operations_completed: int = 0
    operations_failed: int = 0
    intelligence_generated: int = 0
    api_endpoints_discovered: int = 0
    pipelines_executed: int = 0
    cycles_completed: int = 0
    errors: List[str] = field(default_factory=list)
    performance_metrics: Dict[str, Any] = field(default_factory=dict)

class ClisonixIntegrationRunner:
    """
    Runner pÃ«r integrimin e plotÃ« tÃ« Clisonix Intelligence

    Ky klasÃ« orkeston tÃ« gjithÃ« komponentÃ«t pÃ«r njÃ« ekzekutim tÃ« integruar.
    """

    def __init__(self, config: IntegrationConfig):
        self.config = config
        self.metrics = IntegrationMetrics()
        self.active_operations: Set[str] = set()
        self.operation_semaphore = asyncio.Semaphore(config.max_concurrent_operations)

        # Inicializo komponentÃ«t
        self.asi_engine = None
        self.cycle_engine = None
        self.scalability_engine = None
        self.pipeline_builder = None

        # Konfiguro logging
        logging.getLogger().setLevel(getattr(logging, config.log_level))

        logger.info("ğŸš€ Clisonix Integration Runner inicializuar")

    async def initialize_components(self):
        """Inicializon tÃ« gjithÃ« komponentÃ«t"""
        logger.info("ğŸ”§ Inicializimi i komponenteve...")

        if INTEGRATIONS_AVAILABLE:
            try:
                # Inicializo Enhanced ASI
                self.asi_engine = await get_enhanced_asi()
                logger.info("âœ… Enhanced ASI inicializuar")

                # Inicializo Cycle Engine
                self.cycle_engine = await get_cycle_engine()
                logger.info("âœ… Cycle Engine inicializuar")

                # Inicializo Scalability Engine
                self.scalability_engine = await get_scalability_engine()
                logger.info("âœ… Scalability Engine inicializuar")

                # Inicializo Pipeline Builder
                self.pipeline_builder = await get_pipeline_builder()
                logger.info("âœ… Pipeline Builder inicializuar")

            except Exception as e:
                logger.error(f"âŒ Gabim nÃ« inicializim: {e}")
                raise
        else:
            logger.warning("âš ï¸  Integrimet nuk janÃ« tÃ« disponueshme")

    async def run_integration(self) -> Dict[str, Any]:
        """
        Ekzekuton integrimin e plotÃ«

        Bazuar nÃ« modalitetin e konfiguruar, ekzekuton operacionet pÃ«rkatÃ«se.
        """
        logger.info(f"ğŸ¯ Fillimi i integrimit nÃ« modalitet: {self.config.mode.value}")

        try:
            # Inicializo komponentÃ«t
            await self.initialize_components()

            # Ekzekuto bazuar nÃ« modalitet
            if self.config.mode == IntegrationMode.FULL_INTEGRATION:
                result = await self.run_full_integration()
            elif self.config.mode == IntegrationMode.SCALABILITY_FOCUS:
                result = await self.run_scalability_focus()
            elif self.config.mode == IntegrationMode.INTELLIGENCE_FOCUS:
                result = await self.run_intelligence_focus()
            elif self.config.mode == IntegrationMode.API_DISCOVERY:
                result = await self.run_api_discovery()
            elif self.config.mode == IntegrationMode.PIPELINE_EXECUTION:
                result = await self.run_pipeline_execution()
            elif self.config.mode == IntegrationMode.MONITORING_MODE:
                result = await self.run_monitoring_mode()
            else:
                raise ValueError(f"Modalitet i panjohur: {self.config.mode}")

            # PÃ«rfundo metrikat
            self.finalize_metrics()

            logger.info("âœ… Integrimi pÃ«rfunduar me sukses")
            return result

        except Exception as e:
            logger.error(f"âŒ Gabim nÃ« integrim: {e}")
            self.metrics.errors.append(str(e))
            raise

    async def run_full_integration(self) -> Dict[str, Any]:
        """Ekzekuton integrimin e plotÃ«"""
        logger.info("ğŸ”„ Fillimi i integrimit tÃ« plotÃ«...")

        results = {
            'scalability_results': None,
            'intelligence_results': None,
            'pipeline_results': None,
            'api_scan_results': None,
            'cycle_results': None
        }

        # 1. Zbulim dhe pÃ«rpunim i tÃ« dhÃ«nave
        if self.scalability_engine:
            results['scalability_results'] = await self.execute_scalability_cycle()

        # 2. Gjenerim inteligjence
        if self.asi_engine:
            results['intelligence_results'] = await self.execute_intelligence_generation()

        # 3. Ekzekutim pipeline
        if self.pipeline_builder:
            results['pipeline_results'] = await self.execute_pipeline_operations()

        # 4. Skanim API (nÃ«se Ã«shtÃ« aktivizuar)
        if self.config.enable_api_scanning:
            results['api_scan_results'] = await self.execute_api_scanning()

        # 5. Orkestrim cycles
        if self.cycle_engine:
            results['cycle_results'] = await self.execute_cycle_orchestration()

        return results

    async def run_scalability_focus(self) -> Dict[str, Any]:
        """Fokus nÃ« skalabilitet dhe zbulim tÃ« dhÃ«nash"""
        logger.info("ğŸ“ˆ Fillimi i fokusit nÃ« skalabilitet...")

        if not self.scalability_engine:
            raise RuntimeError("Scalability Engine nuk Ã«shtÃ« i disponueshÃ«m")

        # Ekzekuto cikle skalabiliteti
        results = []
        for i in range(3):  # 3 cikle
            result = await self.execute_scalability_cycle()
            results.append(result)
            await asyncio.sleep(1)  # PauzÃ« ndÃ«rmjet cikleve

        return {'scalability_cycles': results}

    async def run_intelligence_focus(self) -> Dict[str, Any]:
        """Fokus nÃ« gjenerimin e inteligjencÃ«s"""
        logger.info("ğŸ§  Fillimi i fokusit nÃ« inteligjencÃ«...")

        if not self.asi_engine:
            raise RuntimeError("Enhanced ASI Engine nuk Ã«shtÃ« i disponueshÃ«m")

        # Gjeneron inteligjencÃ« nÃ« batches
        all_intelligence = []
        batch_count = 5

        for batch in range(batch_count):
            intelligence_batch = await self.execute_intelligence_generation()
            all_intelligence.extend(intelligence_batch)
            await asyncio.sleep(0.5)

        return {'generated_intelligence': all_intelligence}

    async def run_api_discovery(self) -> Dict[str, Any]:
        """Fokus nÃ« zbulimin e API-ve"""
        logger.info("ğŸ” Fillimi i zbulimit tÃ« API-ve...")

        # Skanim i API-ve
        scan_results = await self.execute_api_scanning()

        return {'api_discovery': scan_results}

    async def run_pipeline_execution(self) -> Dict[str, Any]:
        """Fokus nÃ« ekzekutimin e pipeline-ve"""
        logger.info("ğŸ”§ Fillimi i ekzekutimit tÃ« pipeline-ve...")

        if not self.pipeline_builder:
            raise RuntimeError("Pipeline Builder nuk Ã«shtÃ« i disponueshÃ«m")

        # Krijon dhe ekzekuto pipeline tÃ« ndryshme
        pipeline_results = await self.execute_pipeline_operations()

        return {'pipeline_execution': pipeline_results}

    async def run_monitoring_mode(self) -> Dict[str, Any]:
        """Modalitet monitorimi kontinues"""
        logger.info("ğŸ“Š Fillimi i modalitetit monitorues...")

        monitoring_results = {
            'monitoring_duration': self.config.cycle_timeout,
            'metrics_snapshots': [],
            'alerts': []
        }

        start_time = time.time()
        snapshot_interval = 30  # sekonda

        while time.time() - start_time < self.config.cycle_timeout:
            # Merr snapshot tÃ« metrikave
            snapshot = await self.get_system_metrics()
            monitoring_results['metrics_snapshots'].append(snapshot)

            # Kontrollo pÃ«r alerte
            alerts = await self.check_system_alerts(snapshot)
            monitoring_results['alerts'].extend(alerts)

            await asyncio.sleep(snapshot_interval)

        return monitoring_results

    async def execute_scalability_cycle(self) -> Dict[str, Any]:
        """Ekzekuto njÃ« cikÃ«l skalabiliteti"""
        async with self.operation_semaphore:
            operation_id = f"scalability_{uuid.uuid4().hex[:8]}"
            self.active_operations.add(operation_id)

            try:
                logger.info(f"ğŸ“ˆ Ekzekutimi i ciklit skalabilitet: {operation_id}")

                # Merr tÃ« dhÃ«na nga burime tÃ« hapura
                discovery_result = await self.scalability_engine.discover_data_sources()

                # Gjeneron pÃ«rmbajtje inteligjente
                content_result = await self.scalability_engine.generate_intelligent_content(
                    sources=discovery_result.get('sources', []),
                    intelligence_type='api_alignment'
                )

                # PÃ«rditÃ«so metrika
                self.metrics.operations_completed += 1

                result = {
                    'operation_id': operation_id,
                    'discovery_result': discovery_result,
                    'content_result': content_result,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }

                logger.info(f"âœ… CikÃ«l skalabiliteti pÃ«rfunduar: {operation_id}")
                return result

            except Exception as e:
                logger.error(f"âŒ Gabim nÃ« cikÃ«l skalabiliteti {operation_id}: {e}")
                self.metrics.operations_failed += 1
                self.metrics.errors.append(str(e))
                return {'error': str(e), 'operation_id': operation_id}

            finally:
                self.active_operations.discard(operation_id)

    async def execute_intelligence_generation(self) -> List[Dict[str, Any]]:
        """Gjeneron inteligjencÃ« tÃ« re"""
        async with self.operation_semaphore:
            operation_id = f"intelligence_{uuid.uuid4().hex[:8]}"
            self.active_operations.add(operation_id)

            try:
                logger.info(f"ğŸ§  Gjenerimi i inteligjencÃ«s: {operation_id}")

                # Gjeneron koncepte tÃ« reja inteligjente
                new_concepts = await self.asi_engine.generate_new_intelligence_concepts(
                    count=self.config.intelligence_batch_size
                )

                # Krijon njÃ«si inteligjence
                intelligence_units = []
                for concept in new_concepts:
                    unit = await self.asi_engine.create_intelligence_unit(
                        concept=concept,
                        intelligence_type=IntelligenceType.AGI_SYNTHESIS
                    )
                    intelligence_units.append(unit)

                # PÃ«rditÃ«so metrika
                self.metrics.intelligence_generated += len(intelligence_units)
                self.metrics.operations_completed += 1

                result = {
                    'operation_id': operation_id,
                    'new_concepts': len(new_concepts),
                    'intelligence_units': intelligence_units,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }

                logger.info(f"âœ… Inteligjenca gjeneruar: {len(intelligence_units)} njÃ«si")
                return intelligence_units

            except Exception as e:
                logger.error(f"âŒ Gabim nÃ« gjenerimin e inteligjencÃ«s {operation_id}: {e}")
                self.metrics.operations_failed += 1
                self.metrics.errors.append(str(e))
                return []

            finally:
                self.active_operations.discard(operation_id)

    async def execute_pipeline_operations(self) -> Dict[str, Any]:
        """Ekzekuto operacione pipeline"""
        async with self.operation_semaphore:
            operation_id = f"pipeline_{uuid.uuid4().hex[:8]}"
            self.active_operations.add(operation_id)

            try:
                logger.info(f"ğŸ”§ Ekzekutimi i pipeline-ve: {operation_id}")

                # Krijon pipeline tÃ« ndryshme
                pipelines = []

                # Pipeline AI pÃ«rpunimi
                ai_pipeline = await self.pipeline_builder.create_pipeline(
                    "AI Processing Pipeline",
                    PipelineType.AI_PROCESSING
                )
                pipelines.append(ai_pipeline)

                # Pipeline AGI zhvillimi
                agi_pipeline = await self.pipeline_builder.create_pipeline(
                    "AGI Development Pipeline",
                    PipelineType.AGI_DEVELOPMENT
                )
                pipelines.append(agi_pipeline)

                # Ekzekuto pipeline
                execution_results = []
                for pipeline in pipelines:
                    result = await self.pipeline_builder.execute_pipeline(
                        pipeline.id,
                        input_data={"source": "integration_runner", "timestamp": datetime.now(timezone.utc)}
                    )
                    execution_results.append(result)

                # PÃ«rditÃ«so metrika
                self.metrics.pipelines_executed += len(execution_results)
                self.metrics.operations_completed += 1

                result = {
                    'operation_id': operation_id,
                    'pipelines_created': len(pipelines),
                    'executions': execution_results,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }

                logger.info(f"âœ… Pipeline ekzekutuar: {len(execution_results)} rezultate")
                return result

            except Exception as e:
                logger.error(f"âŒ Gabim nÃ« ekzekutimin e pipeline-ve {operation_id}: {e}")
                self.metrics.operations_failed += 1
                self.metrics.errors.append(str(e))
                return {'error': str(e), 'operation_id': operation_id}

            finally:
                self.active_operations.discard(operation_id)

    async def execute_api_scanning(self) -> Dict[str, Any]:
        """Ekzekuto skanim API"""
        async with self.operation_semaphore:
            operation_id = f"api_scan_{uuid.uuid4().hex[:8]}"
            self.active_operations.add(operation_id)

            try:
                logger.info(f"ğŸ” Skanimi i API-ve: {operation_id}")

                # Import dhe ekzekutim i scanner TypeScript (simulim)
                # NÃ« praktikÃ«, do tÃ« thirrej scanner-i TypeScript
                scan_result = {
                    'base_url': 'https://api.clisonix.cloud',
                    'endpoints_discovered': 25,
                    'authenticated_endpoints': 15,
                    'rate_limited_endpoints': 5,
                    'scan_duration': 45000,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }

                # PÃ«rditÃ«so metrika
                self.metrics.api_endpoints_discovered += scan_result['endpoints_discovered']
                self.metrics.operations_completed += 1

                logger.info(f"âœ… API skanuar: {scan_result['endpoints_discovered']} endpoints")
                return scan_result

            except Exception as e:
                logger.error(f"âŒ Gabim nÃ« skanim API {operation_id}: {e}")
                self.metrics.operations_failed += 1
                self.metrics.errors.append(str(e))
                return {'error': str(e), 'operation_id': operation_id}

            finally:
                self.active_operations.discard(operation_id)

    async def execute_cycle_orchestration(self) -> Dict[str, Any]:
        """Ekzekuto orkestrimin e ciklave"""
        async with self.operation_semaphore:
            operation_id = f"cycle_{uuid.uuid4().hex[:8]}"
            self.active_operations.add(operation_id)

            try:
                logger.info(f"ğŸ”„ Orkestrimi i ciklave: {operation_id}")

                # Ekzekuto cikle tÃ« ndryshme
                cycles_executed = []

                # CikÃ«l inteligjence
                intelligence_cycle = await self.cycle_engine.execute_cycle(
                    cycle_type=CycleType.INTELLIGENCE_GENERATION,
                    alignment_policy=AlignmentPolicy.ETHICAL_MAXIMIZATION
                )
                cycles_executed.append(intelligence_cycle)

                # CikÃ«l skalabiliteti
                scalability_cycle = await self.cycle_engine.execute_cycle(
                    cycle_type=CycleType.SCALABILITY_ENGINE,
                    alignment_policy=AlignmentPolicy.RESOURCE_OPTIMIZATION
                )
                cycles_executed.append(scalability_cycle)

                # PÃ«rditÃ«so metrika
                self.metrics.cycles_completed += len(cycles_executed)
                self.metrics.operations_completed += 1

                result = {
                    'operation_id': operation_id,
                    'cycles_executed': cycles_executed,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }

                logger.info(f"âœ… Cikle orkestruar: {len(cycles_executed)} cikle")
                return result

            except Exception as e:
                logger.error(f"âŒ Gabim nÃ« orkestrimin e ciklave {operation_id}: {e}")
                self.metrics.operations_failed += 1
                self.metrics.errors.append(str(e))
                return {'error': str(e), 'operation_id': operation_id}

            finally:
                self.active_operations.discard(operation_id)

    async def get_system_metrics(self) -> Dict[str, Any]:
        """Merr metrika tÃ« sistemit"""
        metrics = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'active_operations': len(self.active_operations),
            'total_operations': self.metrics.operations_completed + self.metrics.operations_failed,
            'success_rate': 0.0,
            'intelligence_generated': self.metrics.intelligence_generated,
            'api_endpoints_discovered': self.metrics.api_endpoints_discovered,
            'pipelines_executed': self.metrics.pipelines_executed,
            'cycles_completed': self.metrics.cycles_completed,
            'errors_count': len(self.metrics.errors)
        }

        # Llogarit shkallÃ«n e suksesit
        total_ops = metrics['total_operations']
        if total_ops > 0:
            metrics['success_rate'] = self.metrics.operations_completed / total_ops

        return metrics

    async def check_system_alerts(self, metrics: Dict[str, Any]) -> List[str]:
        """Kontrollo pÃ«r alerte nÃ« sistem"""
        alerts = []

        # Kontrollo pÃ«r shumÃ« gabime
        if len(self.metrics.errors) > 5:
            alerts.append("âš ï¸  ShumÃ« gabime nÃ« sistem")

        # Kontrollo pÃ«r operacione tÃ« bllokuara
        if len(self.active_operations) > self.config.max_concurrent_operations * 2:
            alerts.append("âš ï¸  ShumÃ« operacione aktive")

        # Kontrollo pÃ«r shkallÃ« tÃ« ulÃ«t suksesi
        if metrics.get('success_rate', 1.0) < 0.7:
            alerts.append("âš ï¸  ShkallÃ« e ulÃ«t suksesi nÃ« operacione")

        return alerts

    def finalize_metrics(self):
        """PÃ«rfundon dhe ruan metrikat"""
        self.metrics.performance_metrics = {
            'total_runtime': (datetime.now(timezone.utc) - self.metrics.start_time).total_seconds(),
            'operations_per_second': self.metrics.operations_completed / max(1, (datetime.now(timezone.utc) - self.metrics.start_time).total_seconds()),
            'error_rate': len(self.metrics.errors) / max(1, self.metrics.operations_completed + self.metrics.operations_failed)
        }

        logger.info("ğŸ“Š Metrika pÃ«rfundimtare:")
        logger.info(f"  âœ… Operacione tÃ« suksesshme: {self.metrics.operations_completed}")
        logger.info(f"  âŒ Operacione tÃ« dÃ«shtuara: {self.metrics.operations_failed}")
        logger.info(f"  ğŸ§  InteligjencÃ« gjeneruar: {self.metrics.intelligence_generated}")
        logger.info(f"  ğŸ” API endpoints zbuluar: {self.metrics.api_endpoints_discovered}")
        logger.info(f"  ğŸ”§ Pipeline ekzekutuar: {self.metrics.pipelines_executed}")
        logger.info(f"  ğŸ”„ Cikle pÃ«rfunduar: {self.metrics.cycles_completed}")

    async def save_results(self, results: Dict[str, Any], output_dir: str = None):
        """Ruan rezultatet nÃ« file"""
        if not output_dir:
            output_dir = self.config.output_directory

        # Krijon direktorinÃ«
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")

        # Ruaj rezultatet kryesore
        results_file = Path(output_dir) / f"integration_results_{timestamp}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)

        # Ruaj metrikat
        metrics_file = Path(output_dir) / f"integration_metrics_{timestamp}.json"
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump({
                'metrics': self.metrics.__dict__,
                'config': self.config.__dict__
            }, f, indent=2, ensure_ascii=False, default=str)

        logger.info(f"ğŸ’¾ Rezultatet ruajtur nÃ«: {output_dir}")

async def main():
    """Funksioni kryesor"""
    parser = argparse.ArgumentParser(description='Clisonix Intelligence Integration Runner')
    parser.add_argument('--mode', choices=[m.value for m in IntegrationMode],
                       default=IntegrationMode.FULL_INTEGRATION.value,
                       help='Modaliteti i integrimit')
    parser.add_argument('--output-dir', default='./integration_output',
                       help='Direktoria pÃ«r rezultatet')
    parser.add_argument('--timeout', type=int, default=300,
                       help='Timeout nÃ« sekonda')
    parser.add_argument('--concurrency', type=int, default=5,
                       help='Numri maksimal i operacioneve konkurrente')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
                       default='INFO', help='Niveli i logging')

    args = parser.parse_args()

    # Krijon konfigurimin
    config = IntegrationConfig(
        mode=IntegrationMode(args.mode),
        output_directory=args.output_dir,
        cycle_timeout=args.timeout,
        max_concurrent_operations=args.concurrency,
        log_level=args.log_level
    )

    # Krijon dhe ekzekuto runner
    runner = ClisonixIntegrationRunner(config)

    try:
        results = await runner.run_integration()

        # Ruaj rezultatet
        await runner.save_results(results, args.output_dir)

        logger.info("ğŸ‰ Integrimi pÃ«rfunduar me sukses!")

    except KeyboardInterrupt:
        logger.info("â¹ï¸  Integrimi ndÃ«rprer nga pÃ«rdoruesi")
    except Exception as e:
        logger.error(f"ğŸ’¥ Gabim fatal: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # Ekzekuto integrimin
    asyncio.run(main())