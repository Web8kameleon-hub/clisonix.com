# ============================================================================
# REASONING ENGINE - Logic and Inference Without External AI
# ============================================================================
# Pure rule-based and pattern-matching reasoning
# NO external LLMs - 100% Internal Clisonix Intelligence
# ============================================================================

import logging
import re
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


# ============================================================================
# DATA CLASSES
# ============================================================================

class ReasoningMethod(Enum):
    """Methods of reasoning available"""
    PATTERN_MATCH = "pattern_match"      # Direct pattern matching
    RULE_BASED = "rule_based"            # Rule-based inference
    STATISTICAL = "statistical"          # Statistical analysis
    AGGREGATION = "aggregation"          # Data aggregation
    COMPARISON = "comparison"            # Comparative analysis
    TEMPORAL = "temporal"                # Time-series reasoning
    HIERARCHICAL = "hierarchical"        # Tree-based reasoning
    GRAPH = "graph"                      # Graph traversal


class ConfidenceLevel(Enum):
    """Confidence levels for results"""
    CERTAIN = "certain"          # 0.95+
    HIGH = "high"                # 0.80-0.95
    MEDIUM = "medium"            # 0.60-0.80
    LOW = "low"                  # 0.40-0.60
    UNCERTAIN = "uncertain"      # <0.40


@dataclass
class InferenceResult:
    """Result of reasoning/inference"""
    answer: str
    sources: List[str]
    method: ReasoningMethod
    confidence: float
    confidence_level: ConfidenceLevel
    reasoning_chain: List[str]
    data_points: int
    processing_time_ms: float
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "answer": self.answer,
            "sources": self.sources,
            "method": self.method.value,
            "confidence": self.confidence,
            "confidence_level": self.confidence_level.value,
            "reasoning_chain": self.reasoning_chain,
            "data_points": self.data_points,
            "processing_time_ms": self.processing_time_ms,
            "metadata": self.metadata
        }


@dataclass
class ReasoningContext:
    """Context for reasoning operations"""
    query: str
    intent: Any  # QueryIntent from knowledge_router
    sources: List[str]
    data: Dict[str, Any]
    constraints: Dict[str, Any] = field(default_factory=dict)
    max_depth: int = 5
    timeout_seconds: float = 30.0


# ============================================================================
# REASONING RULES
# ============================================================================

class ReasoningRules:
    """
    Collection of reasoning rules for different domains
    Each rule is a pattern + inference function
    """
    
    @staticmethod
    def government_rules() -> List[Tuple[str, Callable]]:
        """Rules for government-related queries"""
        return [
            (r"capital of (\w+)", lambda m, ctx: f"The capital of {m.group(1)}"),
            (r"president of (\w+)", lambda m, ctx: f"Current president of {m.group(1)}"),
            (r"government type of (\w+)", lambda m, ctx: f"Government type of {m.group(1)}"),
        ]
    
    @staticmethod
    def statistics_rules() -> List[Tuple[str, Callable]]:
        """Rules for statistics queries"""
        return [
            (r"population of (\w+)", lambda m, ctx: f"Population of {m.group(1)}"),
            (r"gdp of (\w+)", lambda m, ctx: f"GDP of {m.group(1)}"),
            (r"growth rate of (\w+)", lambda m, ctx: f"Growth rate of {m.group(1)}"),
        ]
    
    @staticmethod
    def comparison_rules() -> List[Tuple[str, Callable]]:
        """Rules for comparison queries"""
        return [
            (r"compare (\w+) (?:and|with|vs|versus) (\w+)", 
             lambda m, ctx: f"Comparison between {m.group(1)} and {m.group(2)}"),
            (r"difference between (\w+) and (\w+)",
             lambda m, ctx: f"Difference between {m.group(1)} and {m.group(2)}"),
        ]


# ============================================================================
# REASONING ENGINE CLASS
# ============================================================================

class ReasoningEngine:
    """
    Core reasoning engine for Clisonix Internal AGI
    
    Provides inference capabilities without external LLMs:
    - Rule-based reasoning
    - Pattern matching
    - Statistical aggregation
    - Comparative analysis
    - Temporal reasoning
    
    All logic is internal - no API calls to external AI services.
    """
    
    def __init__(self):
        self.rules = ReasoningRules()
        self._rule_cache: Dict[str, List] = {}
        self._executor = ThreadPoolExecutor(max_workers=4)
        
        # Initialize rule sets
        self._init_rules()
        
        # Knowledge templates for common queries
        self.templates = self._init_templates()
    
    def _init_rules(self):
        """Initialize all reasoning rules"""
        self._rule_cache = {
            "government": self.rules.government_rules(),
            "statistics": self.rules.statistics_rules(),
            "comparison": self.rules.comparison_rules(),
        }
    
    def _init_templates(self) -> Dict[str, str]:
        """Initialize response templates"""
        return {
            "search_result": "Based on {sources} sources from {regions}: {answer}",
            "comparison": "Comparing {entity1} and {entity2}: {findings}",
            "aggregation": "Aggregated from {count} data points: {summary}",
            "not_found": "Unable to find information about {query} in available sources",
            "confidence_low": "Note: This answer has low confidence ({confidence:.0%})",
        }
    
    async def reason(self, context: ReasoningContext) -> InferenceResult:
        """
        Main reasoning method
        
        Takes a context and returns an inference result
        """
        start_time = datetime.now()
        reasoning_chain = []
        
        # Step 1: Analyze query structure
        reasoning_chain.append(f"Analyzing query: '{context.query}'")
        
        # Step 2: Determine best reasoning method
        method = self._select_method(context)
        reasoning_chain.append(f"Selected method: {method.value}")
        
        # Step 3: Apply reasoning
        if method == ReasoningMethod.PATTERN_MATCH:
            answer, data_points = await self._pattern_match_reasoning(context)
        elif method == ReasoningMethod.RULE_BASED:
            answer, data_points = await self._rule_based_reasoning(context)
        elif method == ReasoningMethod.AGGREGATION:
            answer, data_points = await self._aggregation_reasoning(context)
        elif method == ReasoningMethod.COMPARISON:
            answer, data_points = await self._comparison_reasoning(context)
        elif method == ReasoningMethod.STATISTICAL:
            answer, data_points = await self._statistical_reasoning(context)
        else:
            answer, data_points = await self._default_reasoning(context)
        
        reasoning_chain.append(f"Generated answer with {data_points} data points")
        
        # Step 4: Calculate confidence
        confidence = self._calculate_confidence(context, data_points, method)
        confidence_level = self._get_confidence_level(confidence)
        reasoning_chain.append(f"Confidence: {confidence:.2f} ({confidence_level.value})")
        
        # Step 5: Build result
        processing_time = (datetime.now() - start_time).total_seconds() * 1000
        
        return InferenceResult(
            answer=answer,
            sources=context.sources,
            method=method,
            confidence=confidence,
            confidence_level=confidence_level,
            reasoning_chain=reasoning_chain,
            data_points=data_points,
            processing_time_ms=processing_time,
            metadata={
                "query": context.query,
                "intent": context.intent.to_dict() if hasattr(context.intent, 'to_dict') else str(context.intent)
            }
        )
    
    def _select_method(self, context: ReasoningContext) -> ReasoningMethod:
        """Select the best reasoning method for the context"""
        query_lower = context.query.lower()
        
        # Check for comparison patterns
        if any(word in query_lower for word in ["compare", "versus", "vs", "difference"]):
            return ReasoningMethod.COMPARISON
        
        # Check for aggregation patterns
        if any(word in query_lower for word in ["total", "sum", "aggregate", "all"]):
            return ReasoningMethod.AGGREGATION
        
        # Check for statistical patterns
        if any(word in query_lower for word in ["average", "mean", "median", "percent"]):
            return ReasoningMethod.STATISTICAL
        
        # Check for temporal patterns
        if any(word in query_lower for word in ["trend", "history", "over time", "since"]):
            return ReasoningMethod.TEMPORAL
        
        # Check if we have matching rules
        for domain, rules in self._rule_cache.items():
            for pattern, _ in rules:
                if re.search(pattern, query_lower):
                    return ReasoningMethod.RULE_BASED
        
        # Default to pattern matching
        return ReasoningMethod.PATTERN_MATCH
    
    async def _pattern_match_reasoning(self, context: ReasoningContext) -> Tuple[str, int]:
        """Reasoning via pattern matching"""
        query_lower = context.query.lower()
        data_points = 0
        
        # Try to extract answer from available data
        if context.data:
            # Search through data for relevant information
            relevant_items = []
            for key, value in context.data.items():
                if any(keyword in str(value).lower() for keyword in query_lower.split()):
                    relevant_items.append(value)
                    data_points += 1
            
            if relevant_items:
                return f"Found {len(relevant_items)} relevant items: {', '.join(str(x)[:50] for x in relevant_items[:5])}", data_points
        
        # Fallback: provide guidance on where to find info
        return self.templates["not_found"].format(query=context.query), 0
    
    async def _rule_based_reasoning(self, context: ReasoningContext) -> Tuple[str, int]:
        """Reasoning via rule application"""
        query_lower = context.query.lower()
        
        for domain, rules in self._rule_cache.items():
            for pattern, inference_fn in rules:
                match = re.search(pattern, query_lower)
                if match:
                    result = inference_fn(match, context)
                    return result, 1
        
        return await self._pattern_match_reasoning(context)
    
    async def _aggregation_reasoning(self, context: ReasoningContext) -> Tuple[str, int]:
        """Reasoning via data aggregation"""
        data_points: int = 0
        aggregated: list[Any] = []
        
        if context.data:
            for key, value in context.data.items():
                if isinstance(value, (list, tuple)):
                    aggregated.extend(value)
                    data_points += len(value)
                else:
                    aggregated.append(value)
                    data_points += 1
        
        if aggregated:
            return self.templates["aggregation"].format(
                count=data_points,
                summary=f"Combined data from {len(context.sources)} sources"
            ), data_points
        
        return f"No data available to aggregate for: {context.query}", 0
    
    async def _comparison_reasoning(self, context: ReasoningContext) -> Tuple[str, int]:
        """Reasoning via comparison"""
        # Extract entities to compare
        match = re.search(r"compare (\w+) (?:and|with|vs|versus) (\w+)", context.query.lower())
        if match:
            entity1, entity2 = match.groups()
            return self.templates["comparison"].format(
                entity1=entity1,
                entity2=entity2,
                findings="Data comparison pending - sources queried"
            ), 2
        
        return f"Unable to identify comparison entities in: {context.query}", 0
    
    async def _statistical_reasoning(self, context: ReasoningContext) -> Tuple[str, int]:
        """Reasoning via statistical analysis"""
        data_points = 0
        
        if context.data:
            # Look for numeric data
            numbers = []
            for key, value in context.data.items():
                if isinstance(value, (int, float)):
                    numbers.append(value)
                    data_points += 1
            
            if numbers:
                avg = sum(numbers) / len(numbers)
                return f"Statistical summary: Average = {avg:.2f}, Count = {len(numbers)}", data_points
        
        return f"No statistical data available for: {context.query}", 0
    
    async def _default_reasoning(self, context: ReasoningContext) -> Tuple[str, int]:
        """Default reasoning fallback"""
        sources_text = ", ".join(context.sources[:3]) if context.sources else "available sources"
        
        return self.templates["search_result"].format(
            sources=len(context.sources),
            regions=sources_text,
            answer=f"Information about '{context.query}' is being gathered from internal sources"
        ), len(context.sources)
    
    def _calculate_confidence(self, context: ReasoningContext, data_points: int, method: ReasoningMethod) -> float:
        """Calculate confidence score"""
        confidence = 0.5  # Base confidence
        
        # More data points = higher confidence
        if data_points > 0:
            confidence += min(0.2, data_points * 0.02)
        
        # More sources = higher confidence
        if context.sources:
            confidence += min(0.15, len(context.sources) * 0.03)
        
        # Rule-based is more reliable
        if method == ReasoningMethod.RULE_BASED:
            confidence += 0.1
        
        # Aggregation with data is reliable
        if method == ReasoningMethod.AGGREGATION and data_points > 3:
            confidence += 0.1
        
        return min(confidence, 0.99)  # Never 100% confident
    
    def _get_confidence_level(self, confidence: float) -> ConfidenceLevel:
        """Convert confidence score to level"""
        if confidence >= 0.95:
            return ConfidenceLevel.CERTAIN
        elif confidence >= 0.80:
            return ConfidenceLevel.HIGH
        elif confidence >= 0.60:
            return ConfidenceLevel.MEDIUM
        elif confidence >= 0.40:
            return ConfidenceLevel.LOW
        else:
            return ConfidenceLevel.UNCERTAIN
    
    def explain_reasoning(self, result: InferenceResult) -> str:
        """Generate human-readable explanation of reasoning"""
        explanation = [
            "## Reasoning Explanation",
            "",
            f"**Query:** {result.metadata.get('query', 'Unknown')}",
            "",
            f"**Method Used:** {result.method.value}",
            "",
            "**Reasoning Chain:**"
        ]
        
        for i, step in enumerate(result.reasoning_chain, 1):
            explanation.append(f"{i}. {step}")
        
        explanation.extend([
            "",
            "**Result:**",
            f"- Answer: {result.answer[:100]}..." if len(result.answer) > 100 else f"- Answer: {result.answer}",
            f"- Confidence: {result.confidence:.1%} ({result.confidence_level.value})",
            f"- Data Points: {result.data_points}",
            f"- Processing Time: {result.processing_time_ms:.2f}ms",
            f"- Sources: {', '.join(result.sources[:5])}"
        ])
        
        return "\n".join(explanation)


# ============================================================================
# SINGLETON INSTANCE
# ============================================================================

_engine_instance: Optional[ReasoningEngine] = None

def get_engine() -> ReasoningEngine:
    """Get the global reasoning engine singleton"""
    global _engine_instance
    if _engine_instance is None:
        _engine_instance = ReasoningEngine()
    return _engine_instance
