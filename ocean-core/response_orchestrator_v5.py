"""
RESPONSE ORCHESTRATOR V5 - PRODUCTION BRAIN
============================================
Minimal, i shpejtÃ«, 100% lokal, pa API tÃ« jashtme me pagesÃ«.

Features:
- Fast-path conversational (RealAnswerEngine direkt)
- Multilingual hooks (pa Google/DeepL - 100% lokal)
- Timeout pÃ«r ekspertÃ«t
- PÃ«rdor persona/labs/modules vetÃ«m kur ka kuptim
- Zero external paid APIs
- MEGA LAYER ENGINE: ~2.8 MILIARD KOMBINIME
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Tuple
from enum import Enum

# Import Mega Layer Engine
try:
    from mega_layer_engine import get_mega_layer_engine, MegaLayerEngine as MegaLayerEngineClass, LayerActivation
    MEGA_LAYERS_AVAILABLE = True
except ImportError:
    MEGA_LAYERS_AVAILABLE = False
    MegaLayerEngineClass = None
    LayerActivation = None

# Import Knowledge Seeds
try:
    from knowledge_seeds.core_knowledge import find_matching_seed, seed_stats, KnowledgeSeed
    KNOWLEDGE_SEEDS_AVAILABLE = True
except ImportError:
    KNOWLEDGE_SEEDS_AVAILABLE = False
    find_matching_seed = None
    seed_stats = None
    KnowledgeSeed = None

# Import Ollama Multi-Model Engine (5 models: phi3, clisonix-ocean:v2, llama3.1, etc.)
try:
    from ollama_multi_engine import OllamaMultiEngine, Strategy as OllamaStrategy
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False
    OllamaMultiEngine = None
    OllamaStrategy = None

# Import Albanian Dictionary
try:
    from albanian_dictionary import (
        get_albanian_response, 
        detect_albanian, 
        ALL_ALBANIAN_WORDS,
        CLISONIX_TERMS,
        SENTENCE_PATTERNS
    )
    ALBANIAN_DICT_AVAILABLE = True
except ImportError:
    ALBANIAN_DICT_AVAILABLE = False
    get_albanian_response = None
    detect_albanian = None
    ALL_ALBANIAN_WORDS = {}

# Import Smart API Router - DIREKT API thirrje pa Ollama (1% CPU!)
try:
    from smart_api_router import get_smart_router, SmartAPIRouter
    SMART_ROUTER_AVAILABLE = True
except ImportError:
    SMART_ROUTER_AVAILABLE = False
    get_smart_router = None
    SmartAPIRouter = None

logger = logging.getLogger("orchestrator_v5")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ENUMS & DATA CLASSES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class QueryCategory(str, Enum):
    FINANCIAL = "financial"
    PHILOSOPHICAL = "philosophical"
    TECHNICAL = "technical"
    OPERATIONAL = "operational"
    SCIENTIFIC = "scientific"
    NARRATIVE = "narrative"
    PERSONAL = "personal"
    ANALYTICAL = "analytical"
    EXPLORATORY = "exploratory"
    BINARY = "binary"
    CONVERSATIONAL = "conversational"  # PÃ«r chat normal


@dataclass
class ExpertConsultation:
    expert_type: str
    expert_name: str
    expert_id: str
    query_sent: str
    response: str
    confidence: float
    relevance_score: float
    processing_time_ms: float
    timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())


@dataclass
class OrchestratedResponse:
    query: str
    query_category: QueryCategory
    understanding: Dict[str, Any]
    consulted_experts: List[ExpertConsultation]
    fused_answer: str
    sources_cited: List[str]
    confidence: float
    narrative_quality: float
    learning_record: Dict[str, Any]
    language: str = "sq"
    mega_layers: Optional[Dict[str, Any]] = None  # Mega Layer results
    timestamp: str = field(default_factory=lambda: datetime.now(timezone.utc).isoformat())


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  LANGUAGE LAYER - 100% LOKAL (PA API TÃ‹ JASHTME)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class LocalLanguageLayer:
    """
    Multilingual Layer - 100% lokal, pa pagesÃ«, pa cloud.
    
    PÃ«rdor langdetect pÃ«r detektim dhe pÃ«rgjigje lokale pÃ«r Ã§do gjuhÃ«.
    NUK pÃ«rdor Google Translate, DeepL, apo Ã§do API tÃ« jashtme.
    """
    
    def __init__(self):
        self._langdetect_available = False
        try:
            from langdetect import detect as _detect
            self._detect = _detect
            self._langdetect_available = True
        except ImportError:
            self._detect = None
    
    def detect_language(self, text: str) -> str:
        """Detekto gjuhÃ«n - 100% lokal."""
        if not text or len(text.strip()) < 3:
            return "sq"  # Default: Shqip
        
        # Provo langdetect (lokal, pa pagesÃ«)
        if self._langdetect_available and self._detect:
            try:
                return self._detect(text)
            except Exception:
                pass
        
        # Fallback: pattern matching lokal
        text_lower = text.lower()
        
        # Shqip
        sq_markers = ['Ã«', 'Ã§', 'sh', 'zh', 'gj', 'nj', 'xh', 'rr', 'th', 'dh',
                      'Ã«shtÃ«', 'jam', 'je', 'jemi', 'janÃ«', 'kam', 'kemi', 'kanÃ«',
                      'pÃ«rshÃ«ndetje', 'mirÃ«dita', 'Ã§farÃ«', 'pse', 'kush', 'ku', 'kur']
        if any(m in text_lower for m in sq_markers):
            return "sq"
        
        # Gjermanisht
        de_markers = ['Ã¼', 'Ã¶', 'Ã¤', 'ÃŸ', 'ich', 'du', 'ist', 'sind', 'haben', 'werden',
                      'nicht', 'und', 'oder', 'aber', 'kÃ¶nnen', 'mÃ¶chten', 'bitte']
        if any(m in text_lower for m in de_markers):
            return "de"
        
        # FrÃ«ngjisht
        fr_markers = ['Ã©', 'Ã¨', 'Ãª', 'Ã§', 'je', 'tu', 'vous', 'nous', 'est', 'sont',
                      'avoir', 'Ãªtre', 'pourquoi', 'comment', 'bonjour', 'merci']
        if any(m in text_lower for m in fr_markers):
            return "fr"
        
        # Spanjisht
        es_markers = ['Ã±', 'Â¿', 'Â¡', 'soy', 'eres', 'es', 'somos', 'estÃ¡n', 'hola',
                      'gracias', 'por quÃ©', 'cÃ³mo', 'cuÃ¡ndo', 'dÃ³nde', 'quÃ©']
        if any(m in text_lower for m in es_markers):
            return "es"
        
        # Italisht
        it_markers = ['sono', 'sei', 'siamo', 'sono', 'ciao', 'grazie', 'perchÃ©',
                      'come', 'quando', 'dove', 'cosa', 'buongiorno', 'buonasera']
        if any(m in text_lower for m in it_markers):
            return "it"
        
        # Default: Anglisht
        return "en"
    
    async def to_internal(self, text: str, lang: str) -> str:
        """
        Konverto nÃ« gjuhÃ«n interne - NUK pÃ«rkthejmÃ«!
        
        Thjesht e ruajmÃ« query-n origjinale dhe e procesojmÃ« direkt.
        Sistemi ynÃ« kupton shumÃ« gjuhÃ« pa pÃ«rkthim.
        """
        return text  # Proceso direkt - pa pÃ«rkthim!
    
    async def from_internal(self, text: str, lang: str) -> str:
        """
        Konverto nga gjuha interne - NUK pÃ«rkthejmÃ«!
        
        PÃ«rgjigjet gjenerohen direkt nÃ« gjuhÃ«n e kÃ«rkuar.
        """
        return text  # Kthu direkt - pa pÃ«rkthim!
    
    def get_greeting(self, lang: str) -> str:
        """PÃ«rshÃ«ndetje nÃ« gjuhÃ« tÃ« ndryshme."""
        greetings = {
            "sq": "PÃ«rshÃ«ndetje! Jam Curiosity Ocean. Si mund tÃ« tÃ« ndihmoj?",
            "en": "Hello! I'm Curiosity Ocean. How can I help you?",
            "de": "Hallo! Ich bin Curiosity Ocean. Wie kann ich Ihnen helfen?",
            "fr": "Bonjour! Je suis Curiosity Ocean. Comment puis-je vous aider?",
            "es": "Â¡Hola! Soy Curiosity Ocean. Â¿CÃ³mo puedo ayudarte?",
            "it": "Ciao! Sono Curiosity Ocean. Come posso aiutarti?",
            "el": "Î“ÎµÎ¹Î± ÏƒÎ±Ï‚! Î•Î¯Î¼Î±Î¹ Ï„Î¿ Curiosity Ocean. Î ÏÏ‚ Î¼Ï€Î¿ÏÏ Î½Î± ÏƒÎ±Ï‚ Î²Î¿Î·Î¸Î®ÏƒÏ‰;",
            "tr": "Merhaba! Ben Curiosity Ocean. Size nasÄ±l yardÄ±mcÄ± olabilirim?",
            "ru": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ Curiosity Ocean. Ğ§ĞµĞ¼ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ?",
        }
        return greetings.get(lang, greetings["en"])
    
    def get_fallback(self, lang: str, query: str) -> str:
        """Mesazh fallback nÃ« gjuhÃ« tÃ« ndryshme."""
        fallbacks = {
            "sq": f"Faleminderit pÃ«r pyetjen! Po e analizoj: \"{query}\"",
            "en": f"Thanks for your question! I'm analyzing: \"{query}\"",
            "de": f"Danke fÃ¼r Ihre Frage! Ich analysiere: \"{query}\"",
            "fr": f"Merci pour votre question! J'analyse: \"{query}\"",
            "es": f"Â¡Gracias por tu pregunta! Estoy analizando: \"{query}\"",
            "it": f"Grazie per la tua domanda! Sto analizzando: \"{query}\"",
            "el": f"Î•Ï…Ï‡Î±ÏÎ¹ÏƒÏ„Ï Î³Î¹Î± Ï„Î·Î½ ÎµÏÏÏ„Î·ÏƒÎ·! Î‘Î½Î±Î»ÏÏ‰: \"{query}\"",
            "tr": f"Soru iÃ§in teÅŸekkÃ¼rler! Analiz ediyorum: \"{query}\"",
            "ru": f"Ğ¡Ğ¿Ğ°ÑĞ¸Ğ±Ğ¾ Ğ·Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ! ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ: \"{query}\"",
        }
        return fallbacks.get(lang, fallbacks["en"])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  LANGUAGE REQUEST DETECTOR - Detects explicit language commands
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Language request patterns - maps phrases to ISO language codes
LANGUAGE_REQUEST_PATTERNS = {
    # Albanian requests
    "nÃ« gjermanisht": "de",
    "nÃ« anglisht": "en", 
    "nÃ« italisht": "it",
    "nÃ« frÃ«ngjisht": "fr",
    "nÃ« spanjisht": "es",
    "nÃ« greqisht": "el",
    "nÃ« turqisht": "tr",
    "nÃ« rusisht": "ru",
    "nÃ« shqip": "sq",
    "pÃ«rgjigju nÃ« gjermanisht": "de",
    "pÃ«rgjigju nÃ« anglisht": "en",
    "pÃ«rgjigju nÃ« italisht": "it",
    "pÃ«rgjigju nÃ« frÃ«ngjisht": "fr",
    "pÃ«rgjigju nÃ« greqisht": "el",
    "pÃ«rgjigju nÃ« shqip": "sq",
    
    # English requests
    "in german": "de",
    "in english": "en",
    "in italian": "it",
    "in french": "fr",
    "in spanish": "es",
    "in greek": "el",
    "in turkish": "tr",
    "in russian": "ru",
    "in albanian": "sq",
    "respond in german": "de",
    "respond in english": "en",
    "reply in german": "de",
    "answer in german": "de",
    
    # German requests
    "auf deutsch": "de",
    "auf englisch": "en",
    "auf italienisch": "it",
    "auf franzÃ¶sisch": "fr",
    "auf spanisch": "es",
    "antworte auf deutsch": "de",
    "antworte auf englisch": "en",
    
    # Italian requests  
    "in italiano": "it",
    "in inglese": "en",
    "in tedesco": "de",
    "rispondi in italiano": "it",
    "rispondi in inglese": "en",
    
    # French requests
    "en franÃ§ais": "fr",
    "en anglais": "en",
    "en allemand": "de",
    "rÃ©ponds en franÃ§ais": "fr",
    "rÃ©ponds en anglais": "en",
    
    # Greek requests (romanized)
    "sta ellinika": "el",
    "sta agglika": "en",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  EXPERT REGISTRY - MINIMAL, PRODUCTION-FRIENDLY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ExpertRegistryV5:
    """
    Regjistri minimal i ekspertÃ«ve.
    VetÃ«m 1 persona + 1 lab + 1 modul pÃ«r kategori.
    """
    
    def __init__(self):
        self.personas = {
            "smart_human": {"id": "ps_009", "domain": "personal"},
            "systems_architect": {"id": "ps_004", "domain": "technical"},
            "business_analyst": {"id": "ps_008", "domain": "financial"},
            "agi_analyst": {"id": "ps_007", "domain": "philosophical"},
            "scientist": {"id": "ps_010", "domain": "scientific"},
        }
        self.labs = {
            "Budapest_Data": {"id": "lab_data", "domain": "analytical"},
            "Vienna_Neuroscience": {"id": "lab_neuro", "domain": "scientific"},
            "Pristina_Finance": {"id": "lab_fin", "domain": "financial"},
            "Tirana_Tech": {"id": "lab_tech", "domain": "technical"},
        }
        self.modules = {
            "Albi": {"id": "mod_albi", "domain": "financial"},
            "Jona": {"id": "mod_jona", "domain": "philosophical"},
            "Alba": {"id": "mod_alba", "domain": "technical"},
        }

    def pick_minimal_experts(self, category: QueryCategory) -> Dict[str, List[Dict[str, Any]]]:
        """Zgjidh maksimum 1 persona, 1 lab, 1 modul pÃ«r kategorinÃ«."""
        res = {"personas": [], "labs": [], "modules": []}
        
        category_value = category.value if hasattr(category, 'value') else str(category)
        
        # Zgjidh 1 persona
        for name, meta in self.personas.items():
            if meta["domain"] == category_value:
                res["personas"].append({"name": name, **meta})
                break
        
        # Zgjidh 1 lab
        for name, meta in self.labs.items():
            if meta["domain"] == category_value:
                res["labs"].append({"name": name, **meta})
                break
        
        # Zgjidh 1 modul
        for name, meta in self.modules.items():
            if meta["domain"] == category_value:
                res["modules"].append({"name": name, **meta})
                break
        
        return res


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  QUERY UNDERSTANDING - LIGHTWEIGHT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class QueryUnderstandingV5:
    """Kuptimi i shpejtÃ« i query-ve."""
    
    @staticmethod
    def categorize(query: str) -> QueryCategory:
        """Kategorizim i shpejtÃ« bazuar nÃ« fjalÃ« kyÃ§e."""
        q = query.lower()
        
        # PÃ«rshÃ«ndetje/Chat normal
        greetings = ['hello', 'hi', 'hey', 'pÃ«rshÃ«ndetje', 'mirÃ«dita', 'Ã§kemi', 
                     'tungjatjeta', 'si je', 'ciao', 'hola', 'bonjour', 'hallo']
        if any(g in q for g in greetings):
            return QueryCategory.CONVERSATIONAL
        
        # Financiare
        if any(w in q for w in ["invest", "money", "profit", "revenue", "market", 
                                 "stock", "biznes", "para", "fitim", "treg"]):
            return QueryCategory.FINANCIAL
        
        # Filozofike
        if any(w in q for w in ["agi", "conscious", "mind", "meaning", "philosophy",
                                 "ndÃ«rgjegje", "vetÃ«dije", "kuptim", "filozofi"]):
            return QueryCategory.PHILOSOPHICAL
        
        # Teknike
        if any(w in q for w in ["api", "deploy", "server", "database", "kubernetes",
                                 "infrastrukturÃ«", "kod", "code", "program"]):
            return QueryCategory.TECHNICAL
        
        # Operacionale
        if any(w in q for w in ["process", "workflow", "operacion", "prodhim", "cycle"]):
            return QueryCategory.OPERATIONAL
        
        # Shkencore
        if any(w in q for w in ["research", "experiment", "data", "study", 
                                 "teori", "shkencÃ«", "science"]):
            return QueryCategory.SCIENTIFIC
        
        # Narrative
        if any(w in q for w in ["story", "tregim", "explain", "shpjego", "histori"]):
            return QueryCategory.NARRATIVE
        
        # Personale
        if any(w in q for w in ["help", "ndihmÃ«", "ndihme", "mendim", "kÃ«shillÃ«", "advice"]):
            return QueryCategory.PERSONAL
        
        # Analitike
        if any(w in q for w in ["analyze", "analizo", "statistikÃ«", "trend", "pattern"]):
            return QueryCategory.ANALYTICAL
        
        # Binare
        if any(w in q for w in ["xor", "and", "or", "binary", "bits", "binar"]):
            return QueryCategory.BINARY
        
        return QueryCategory.EXPLORATORY
    
    @staticmethod
    def understand(query: str, context: Optional[List[str]] = None) -> Dict[str, Any]:
        """Kuptimi i plotÃ« i query-t."""
        return {
            "query": query,
            "category": QueryUnderstandingV5.categorize(query),
            "context_len": len(context or []),
            "word_count": len(query.split()),
            "complexity": "simple" if len(query.split()) < 15 else "medium",
        }
    
    @staticmethod
    def needs_experts(category: QueryCategory) -> bool:
        """A duhen ekspertÃ« pÃ«r kÃ«tÃ« kategori?"""
        # PÃ«r chat normal dhe eksplorues, NUK duhen ekspertÃ«
        if category in {QueryCategory.CONVERSATIONAL, QueryCategory.EXPLORATORY}:
            return False
        
        # PÃ«r pyetje komplekse, mund tÃ« duhen
        return category in {
            QueryCategory.FINANCIAL, 
            QueryCategory.TECHNICAL, 
            QueryCategory.SCIENTIFIC,
            QueryCategory.ANALYTICAL
        }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  RESPONSE FUSION - MINIMAL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class FusionEngineV5:
    """Bashko pÃ«rgjigjet nga burime tÃ« ndryshme."""
    
    def fuse(self, base_answer: str, expert_responses: List[ExpertConsultation]) -> Tuple[str, float]:
        """Bashko pÃ«rgjigjen bazÃ« me inputet e ekspertÃ«ve."""
        if not expert_responses:
            return base_answer, 0.9
        
        # Filtro vetÃ«m pÃ«rgjigjet me konfidencÃ« tÃ« lartÃ«
        valid_extras = []
        for c in expert_responses:
            if c.confidence > 0.6 and c.relevance_score > 0.5:
                valid_extras.append(c.response)
        
        if not valid_extras:
            return base_answer, 0.9
        
        # Bashko (maksimum 2 shtesa)
        fused = base_answer + "\n\nğŸ“Š **ShtesÃ« nga sisteme tÃ« tjera:**\n"
        for e in valid_extras[:2]:
            fused += f"â€¢ {e.strip()}\n"
        
        quality = min(1.0, 0.8 + 0.1 * min(len(valid_extras), 2))
        return fused, quality


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  MAIN ORCHESTRATOR V5
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ResponseOrchestratorV5:
    """
    Curiosity Ocean v5 â€“ Production Brain
    
    100% LOKAL - PA API TÃ‹ JASHTME ME PAGESÃ‹
    
    Features:
    - Fast conversational path (RealAnswerEngine)
    - Minimal experts (1 persona, 1 lab, 1 module) - vetÃ«m kur duhen
    - Multilingual hooks (pa Google/DeepL)
    - Timeouts pÃ«r ekspertÃ«t
    - Zero external paid APIs
    - MEGA LAYER ENGINE: ~2.8 MILIARD KOMBINIME UNIKE
    """

    def __init__(
        self,
        real_answer_engine=None,
        language_layer: LocalLanguageLayer = None,
        expert_registry: ExpertRegistryV5 = None,
        fusion_engine: FusionEngineV5 = None,
        expert_timeout_ms: int = 500,
    ):
        self.real_answer_engine = real_answer_engine
        self.language_layer = language_layer or LocalLanguageLayer()
        self.registry = expert_registry or ExpertRegistryV5()
        self.fusion = fusion_engine or FusionEngineV5()
        self.expert_timeout_ms = expert_timeout_ms
        self.learning_history: List[Dict[str, Any]] = []
        
        # Initialize Mega Layer Engine
        self.mega_layer_engine: Optional[Any] = None
        if MEGA_LAYERS_AVAILABLE:
            try:
                self.mega_layer_engine = get_mega_layer_engine()
                logger.info(f"âœ… MegaLayerEngine initialized - {self.mega_layer_engine.total_combinations:,} kombinime")
            except Exception as e:
                logger.warning(f"âš ï¸ MegaLayerEngine not available: {e}")
        
        # Initialize Ollama Multi-Model Engine (5 models with AUTO strategy)
        self.ollama_engine: Optional[Any] = None
        if OLLAMA_AVAILABLE:
            try:
                self.ollama_engine = OllamaMultiEngine(default_strategy=OllamaStrategy.AUTO)
                logger.info("ğŸ¦™ OllamaMultiEngine initialized (5 models, AUTO strategy)")
            except Exception as e:
                logger.warning(f"âš ï¸ OllamaMultiEngine not available: {e}")
        
        # Initialize Smart API Router - DIREKT API thirrje (1% CPU vs 800%!)
        self.smart_router: Optional[Any] = None
        if SMART_ROUTER_AVAILABLE:
            try:
                self.smart_router = get_smart_router()
                logger.info("ğŸš€ SmartAPIRouter initialized - direkt API thirrje aktive!")
            except Exception as e:
                logger.warning(f"âš ï¸ SmartAPIRouter not available: {e}")
        
        # Lazy load RealAnswerEngine nÃ«se nuk u dha
        if self.real_answer_engine is None:
            self._lazy_load_engine()
    
    def _lazy_load_engine(self):
        """Ngarko RealAnswerEngine lazy."""
        try:
            from real_answer_engine import get_real_answer_engine
            self.real_answer_engine = get_real_answer_engine()
            # Sigurohu qÃ« Ã«shtÃ« nÃ« mode conversational
            self.real_answer_engine.RESPONSE_MODE = "conversational"
            logger.info("âœ… RealAnswerEngine loaded (conversational mode)")
        except ImportError as e:
            logger.warning(f"âš ï¸ RealAnswerEngine not available: {e}")
            self.real_answer_engine = None

    def _detect_language_request(self, query: str) -> Optional[str]:
        """
        Detect explicit language request in query.
        
        Examples:
          - "PÃ«rgjigju nÃ« gjermanisht: ..." â†’ returns "de"
          - "Respond in French: ..." â†’ returns "fr"
          - "Antworte auf Englisch: ..." â†’ returns "en"
          
        Returns:
            ISO language code if explicit request found, None otherwise.
        """
        q_lower = query.lower()
        
        # Check all patterns (longest match first for accuracy)
        sorted_patterns = sorted(LANGUAGE_REQUEST_PATTERNS.keys(), key=len, reverse=True)
        
        for pattern in sorted_patterns:
            if pattern in q_lower:
                lang_code = LANGUAGE_REQUEST_PATTERNS[pattern]
                logger.info(f"ğŸŒ Language request detected: '{pattern}' â†’ {lang_code}")
                return lang_code
        
        return None

    async def orchestrate(
        self,
        query: str,
        conversation_context: Optional[List[str]] = None,
        mode: str = "conversational",
    ) -> OrchestratedResponse:
        """
        Orkestro pÃ«rgjigjen.
        
        mode:
          - "conversational": fast path - RealAnswerEngine direkt (DEFAULT)
          - "deep": pÃ«rdor edhe ekspertÃ« aktivikisht
        """
        conversation_context = conversation_context or []
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # 0) LANGUAGE REQUEST DETECTION - HIGHEST PRIORITY
        # Detect if user explicitly requests a specific response language
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        requested_language = self._detect_language_request(query)
        
        # 1) Language detection (100% lokal)
        detected_lang = self.language_layer.detect_language(query)
        
        # Use requested language if specified, otherwise use detected
        lang = requested_language if requested_language else detected_lang
        
        # 2) Query understanding
        understanding = QueryUnderstandingV5.understand(query, conversation_context)
        category: QueryCategory = understanding["category"]
        
        # 3) FAST PATH - RealAnswerEngine direkt
        base_text = ""
        sources = []
        base_confidence = 0.9
        used_knowledge_seed = False
        used_ollama = False
        used_albanian_dict = False
        used_smart_router = False
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # SMART API ROUTER - PRIORITETI MÃ‹ I LARTÃ‹! (1% CPU, <100ms)
        # ThÃ«rras API-tÃ« e brendshme direkt PA Ollama kur Ã«shtÃ« e mundur
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if self.smart_router:
            try:
                smart_result = await self.smart_router.route(query, lang)
                if smart_result.answered:
                    base_text = smart_result.response
                    sources = [smart_result.source]
                    base_confidence = 0.95  # High confidence for direct API
                    used_smart_router = True
                    logger.info(f"ğŸš€ SmartRouter answered ({smart_result.processing_time_ms:.0f}ms) - SKIPPING OLLAMA!")
            except Exception as e:
                logger.warning(f"SmartRouter error: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LANGUAGE OVERRIDE for Ollama - inject language instruction
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        language_override_prompt = None
        if requested_language:
            lang_names = {
                "de": "German (Deutsch)", "en": "English", "it": "Italian (Italiano)",
                "fr": "French (FranÃ§ais)", "es": "Spanish (EspaÃ±ol)", "el": "Greek (Î•Î»Î»Î·Î½Î¹ÎºÎ¬)",
                "tr": "Turkish (TÃ¼rkÃ§e)", "ru": "Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹)", "sq": "Albanian (Shqip)",
                "pt": "Portuguese", "nl": "Dutch", "pl": "Polish", "ja": "Japanese", "zh": "Chinese"
            }
            lang_name = lang_names.get(requested_language, requested_language.upper())
            language_override_prompt = f"CRITICAL: Respond ONLY in {lang_name}. Do not use any other language."
            logger.info(f"ğŸŒ Language override active: {lang_name}")
        
        # OLLAMA - VETÃ‹M nÃ«se SmartRouter nuk u pÃ«rgjigj!
        if not used_smart_router and self.ollama_engine:
            try:
                await self.ollama_engine.initialize()
                
                # Build enhanced query with language instruction
                enhanced_query = query
                if language_override_prompt:
                    enhanced_query = f"[{language_override_prompt}]\n\n{query}"
                
                ollama_response = await self.ollama_engine.generate(enhanced_query)
                if ollama_response.content and not ollama_response.content.startswith("âš ï¸") and not ollama_response.content.startswith("[WARN]"):
                    base_text = ollama_response.content
                    sources = [f"ollama:{ollama_response.model_used}"]
                    base_confidence = 0.90 if ollama_response.tier.value == "balanced" else 0.85
                    used_ollama = True
                    logger.info(f"ğŸ¦™ Ollama [{ollama_response.model_used}] response ({ollama_response.total_duration_ms:.0f}ms)")
            except Exception as e:
                logger.warning(f"Ollama error: {e}")
        
        # 3.3) Fallback to RealAnswerEngine if nothing else answered
        if not used_smart_router and not used_knowledge_seed and not used_albanian_dict and not used_ollama and self.real_answer_engine:
            try:
                base_result = await self.real_answer_engine.answer(query)
                base_text = base_result.answer
                sources = [base_result.source]
                base_confidence = base_result.confidence
            except Exception as e:
                logger.error(f"RealAnswerEngine error: {e}")
                base_text = self.language_layer.get_fallback(lang, query)
                sources = ["fallback"]
        elif not used_smart_router and not used_knowledge_seed and not used_albanian_dict and not used_ollama:
            base_text = self.language_layer.get_fallback(lang, query)
            sources = ["no_engine"]
        
        # 4) EkspertÃ« - VETÃ‹M kur ka sens dhe mode == "deep"
        consulted: List[ExpertConsultation] = []
        
        if mode == "deep" and QueryUnderstandingV5.needs_experts(category):
            experts = self.registry.pick_minimal_experts(category)
            consulted = await self._consult_experts_parallel(query, experts)
        
        # 5) Fusion (vetÃ«m nÃ«se kemi rezultate nga ekspertÃ«)
        fused_answer, quality = self.fusion.fuse(base_text, consulted)
        
        # 5.5) MEGA LAYER PROCESSING - Miliarda kombinime
        # DISABLED for clean chat - layer analysis stored but NOT shown to user
        mega_layer_results = None
        layer_summary = ""
        if self.mega_layer_engine:
            try:
                activation, mega_results = self.mega_layer_engine.process_query(query)
                mega_layer_results = mega_results
                layer_summary = self.mega_layer_engine.get_layer_summary(activation, mega_results)
                
                # DO NOT add layer summary to chat response - keep it clean!
                # fused_answer = fused_answer + layer_summary  # DISABLED
                sources.append("mega_layers_engine")
                
                # Update understanding with layer info
                understanding["mega_layers"] = {
                    "combinations_used": mega_results["combinations_used"],
                    "total_layers_engaged": mega_results["total_layers_engaged"],
                    "unique_signature": mega_results["unique_signature"],
                    "meta_consciousness": mega_results["meta_consciousness"],
                    "quantum_amplitude": mega_results["quantum_amplitude"],
                    "fractal_depth": mega_results["fractal_depth_used"],
                }
            except Exception as e:
                logger.warning(f"MegaLayerEngine processing error: {e}")
        
        # 6) NdÃ«rto pÃ«rgjigjen finale
        response = OrchestratedResponse(
            query=query,
            query_category=category,
            understanding=understanding,
            consulted_experts=consulted,
            fused_answer=fused_answer,
            sources_cited=sources,
            confidence=base_confidence,
            narrative_quality=quality,
            language=lang,
            mega_layers=mega_layer_results,
            learning_record={
                "mode": mode, 
                "lang": lang,
                "experts_used": len(consulted),
                "mega_layers_active": mega_layer_results is not None,
                "combinations_used": mega_layer_results.get("combinations_used", 0) if mega_layer_results else 0,
            },
        )
        
        # 7) Learning history
        self.learning_history.append({
            "query": query,
            "category": category.value,
            "mode": mode,
            "lang": lang,
            "timestamp": response.timestamp,
        })
        
        return response

    async def _consult_experts_parallel(
        self,
        query: str,
        experts: Dict[str, List[Dict[str, Any]]],
    ) -> List[ExpertConsultation]:
        """Konsulto ekspertÃ«t nÃ« paralel me timeout."""
        tasks = []
        
        for p in experts.get("personas", []):
            tasks.append(self._call_expert("persona", p["name"], p["id"], query))
        
        for l in experts.get("labs", []):
            tasks.append(self._call_expert("lab", l["name"], l["id"], query))
        
        for m in experts.get("modules", []):
            tasks.append(self._call_expert("module", m["name"], m["id"], query))
        
        if not tasks:
            return []
        
        # Timeout
        timeout = self.expert_timeout_ms / 1000.0
        try:
            done, pending = await asyncio.wait(tasks, timeout=timeout)
            
            # Anulo tasks qÃ« nuk pÃ«rfunduan
            for p in pending:
                p.cancel()
            
            # Mblidh rezultatet
            results: List[ExpertConsultation] = []
            for d in done:
                try:
                    c = d.result()
                    if c is not None:
                        results.append(c)
                except Exception as e:
                    logger.warning(f"Expert call failed: {e}")
            
            return results
        except Exception as e:
            logger.error(f"Expert consultation error: {e}")
            return []

    async def _call_expert(
        self,
        expert_type: str,
        name: str,
        expert_id: str,
        query: str,
    ) -> Optional[ExpertConsultation]:
        """
        Thirr njÃ« ekspert.
        
        TODO: Lidhe me persona/lab/module tÃ« vÃ«rtetÃ«.
        PÃ«r tani: stub bazÃ«.
        """
        start = datetime.now(timezone.utc)
        try:
            # Simulim i shkurtÃ«r (do tÃ« zÃ«vendÃ«sohet me lidhje reale)
            await asyncio.sleep(0.02)
            
            # Stub response - zÃ«vendÃ«so me logjikÃ« reale
            response = f"[{expert_type}:{name}] NÃ« zhvillim - struktura gati pÃ«r lidhje."
            confidence = 0.5
            relevance = 0.4
            
            elapsed_ms = (datetime.now(timezone.utc) - start).total_seconds() * 1000.0
            
            return ExpertConsultation(
                expert_type=expert_type,
                expert_name=name,
                expert_id=expert_id,
                query_sent=query,
                response=response,
                confidence=confidence,
                relevance_score=relevance,
                processing_time_ms=elapsed_ms,
            )
        except Exception as e:
            logger.warning(f"Error calling expert {expert_type}:{name}: {e}")
            return None
    
    async def quick_answer(self, query: str) -> str:
        """
        PÃ«rgjigje e shpejtÃ« - pa ekspertÃ«, pa overhead.
        Ideal pÃ«r chat normal.
        """
        if self.real_answer_engine:
            try:
                result = await self.real_answer_engine.answer(query)
                return result.answer
            except Exception as e:
                logger.error(f"Quick answer error: {e}")
        
        lang = self.language_layer.detect_language(query)
        return self.language_layer.get_fallback(lang, query)
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistika tÃ« orchestrator-it."""
        return {
            "engine_active": self.real_answer_engine is not None,
            "learning_history_count": len(self.learning_history),
            "expert_timeout_ms": self.expert_timeout_ms,
            "version": "v5_production",
        }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ALIAS for backwards compatibility with ocean_api.py
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    async def process_query_async(
        self, 
        query: str, 
        conversation_context: Optional[List[str]] = None
    ) -> OrchestratedResponse:
        """Alias for orchestrate() - backwards compatibility."""
        return await self.orchestrate(query, conversation_context, mode="conversational")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  SINGLETON & FACTORY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_orchestrator: Optional[ResponseOrchestratorV5] = None


def get_orchestrator_v5() -> ResponseOrchestratorV5:
    """Merr instancÃ«n singleton tÃ« Orchestrator v5."""
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = ResponseOrchestratorV5()
    return _orchestrator


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  TEST
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    import sys
    logging.basicConfig(level=logging.INFO)
    
    async def test():
        print("\n" + "="*60)
        print("ğŸ§ª ORCHESTRATOR V5 TEST - PRODUCTION BRAIN")
        print("="*60)
        
        orch = get_orchestrator_v5()
        
        tests = [
            "PÃ«rshÃ«ndetje!",
            "Hello, how are you?",
            "Sa bÃ«jnÃ« 15 + 27?",
            "What is the date today?",
            "Ã‡farÃ« Ã«shtÃ« Curiosity Ocean?",
            "Hola, Â¿cÃ³mo estÃ¡s?",
            "Bonjour, comment Ã§a va?",
        ]
        
        for query in tests:
            print(f"\nğŸ“ Query: {query}")
            response = await orch.orchestrate(query)
            print(f"ğŸŒ Language: {response.language}")
            print(f"ğŸ“Š Category: {response.query_category.value}")
            print(f"ğŸ“„ Answer: {response.fused_answer[:200]}...")
            print(f"ğŸ“ˆ Confidence: {response.confidence:.0%}")
        
        print("\n" + "="*60)
        print("ğŸ“Š Stats:", orch.get_stats())
    
    asyncio.run(test())
