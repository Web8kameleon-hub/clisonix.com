# -*- coding: utf-8 -*-
"""
ğŸ” OPEN DATA SCALABILITY ENGINE
================================
Moduli i skalabilitetit qÃ« gjen dhe integrojnÃ« burime tÃ« hapura tÃ« tÃ« dhÃ«nave falas,
ushqen tÃ« gjithÃ« modulet inteligjente dhe prodhon kÃ«rkime tÃ« reja, koncepte futuristike,
API alignments, cycles, dokumentacione dhe simulime mbi tÃ« dhÃ«na reale.

Siguruar me JONA oversight pÃ«r etikÃ« dhe siguri.
"""

from __future__ import annotations
import asyncio
import json
import uuid
import requests
import aiohttp
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import re
import urllib.parse
from urllib.robotparser import RobotFileParser
import time
import hashlib
from concurrent.futures import ThreadPoolExecutor
import logging

# Konfigurimi i logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from cycle_engine import CycleEngine, CycleDefinition, CycleType, AlignmentPolicy
    from jona_character import get_jona
    JONA_AVAILABLE = True
except ImportError:
    logger.warning("CycleEngine ose JONA nuk janÃ« tÃ« disponueshme")
    JONA_AVAILABLE = False

class DataSourceType(Enum):
    """Llojet e burimeve tÃ« tÃ« dhÃ«nave"""
    ACADEMIC = "academic"          # Universitetet, kÃ«rkimet shkencore
    GOVERNMENT = "government"      # Qeveria, agjencitÃ« shtetÃ«rore
    RESEARCH = "research"          # Qendrat kÃ«rkimore (CERN, NASA, etj)
    ENVIRONMENTAL = "environmental" # TÃ« dhÃ«na mjedisore
    HEALTH = "health"              # TÃ« dhÃ«na shÃ«ndetÃ«sore, klinika
    ECONOMIC = "economic"          # TÃ« dhÃ«na ekonomike
    SOCIAL = "social"              # TÃ« dhÃ«na sociale
    OPEN_DATA = "open_data"        # Portale tÃ« hapura tÃ« tÃ« dhÃ«nave

class DataQuality(Enum):
    """CilÃ«sia e tÃ« dhÃ«nave"""
    EXCELLENT = "excellent"        # TÃ« dhÃ«na shumÃ« tÃ« besueshme
    GOOD = "good"                  # TÃ« dhÃ«na tÃ« besueshme
    FAIR = "fair"                  # TÃ« dhÃ«na mesatare
    POOR = "poor"                  # TÃ« dhÃ«na me probleme
    UNVERIFIED = "unverified"      # TÃ« dhÃ«na tÃ« paverifikuara

@dataclass
class OpenDataSource:
    """Burim i hapur i tÃ« dhÃ«nave"""
    id: str = field(default_factory=lambda: f"ods_{uuid.uuid4().hex[:12]}")
    url: str = ""
    name: str = ""
    description: str = ""
    source_type: DataSourceType = DataSourceType.OPEN_DATA
    quality_score: DataQuality = DataQuality.UNVERIFIED
    api_endpoints: List[str] = field(default_factory=list)
    data_formats: List[str] = field(default_factory=list)
    update_frequency: Optional[str] = None
    last_verified: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    discovered_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    active: bool = True

@dataclass
class ScalabilityMetrics:
    """Metrikat e skalabilitetit"""
    total_sources_discovered: int = 0
    active_sources: int = 0
    data_ingested_gb: float = 0.0
    cycles_generated: int = 0
    apis_created: int = 0
    research_papers_generated: int = 0
    simulations_run: int = 0
    safety_violations: int = 0
    jona_reviews: int = 0

class OpenDataScalabilityEngine:
    """
    Motori i Skalabilitetit pÃ«r tÃ« DhÃ«na tÃ« Hapura

    Gjen burime tÃ« hapura, i integrojnÃ« dhe ushqen modulet inteligjente
    pÃ«r tÃ« prodhuar kÃ«rkime tÃ« reja dhe koncepte futuristike.
    """

    def __init__(self, cycle_engine: Optional[Any] = None):
        self.cycle_engine = cycle_engine
        self.sources: Dict[str, OpenDataSource] = {}
        self.metrics = ScalabilityMetrics()
        self.discovery_queue: asyncio.Queue = asyncio.Queue()
        self.processing_queue: asyncio.Queue = asyncio.Queue()
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.session: Optional[aiohttp.ClientSession] = None

        # Burime fillestare tÃ« njohura
        self.known_sources = self._load_known_sources()

        # JONA oversight
        self.jona = get_jona() if JONA_AVAILABLE else None

        logger.info("ğŸš€ Open Data Scalability Engine inicializuar")

    def _load_known_sources(self) -> Dict[str, OpenDataSource]:
        """Ngarkon burime tÃ« njohura fillestare"""
        sources = {}

        # Burime akademike dhe kÃ«rkimore
        academic_sources = [
            ("https://pubmed.ncbi.nlm.nih.gov/", "PubMed", DataSourceType.HEALTH),
            ("https://arxiv.org/", "ArXiv", DataSourceType.RESEARCH),
            ("https://www.crossref.org/", "CrossRef", DataSourceType.RESEARCH),
            ("https://www.ncbi.nlm.nih.gov/", "NCBI", DataSourceType.HEALTH),
            ("https://www.ebi.ac.uk/", "EBI", DataSourceType.RESEARCH),
            ("https://www.uniprot.org/", "UniProt", DataSourceType.RESEARCH),
        ]

        for url, name, source_type in academic_sources:
            source = OpenDataSource(
                url=url,
                name=name,
                source_type=source_type,
                quality_score=DataQuality.EXCELLENT
            )
            sources[source.id] = source

        return sources

    async def initialize(self):
        """Inicializon motorin"""
        self.session = aiohttp.ClientSession(
            timeout=aiohttp.ClientTimeout(total=30),
            headers={'User-Agent': 'Clisonix-Scalability-Engine/1.0'}
        )

        # Ngarkon burime ekzistuese nga disku
        await self._load_sources_from_disk()

        logger.info(f"âœ… Inicializuar me {len(self.sources)} burime")

    async def discover_data_sources(self, domains: List[str] = None) -> List[OpenDataSource]:
        """
        Zbulon burime tÃ« reja tÃ« tÃ« dhÃ«nave nga domain-et e specifikuara

        Args:
            domains: Lista e domain-eve pÃ«r kÃ«rkim (universitete, qeveri, etj)
        """
        if domains is None:
            domains = [
                ".edu", ".ac.", ".gov", ".org", ".eu", ".uk", ".de", ".fr",
                "cern.ch", "nasa.gov", "who.int", "un.org", "worldbank.org"
            ]

        discovered_sources = []

        for domain in domains:
            try:
                # KÃ«rkon pÃ«r burime tÃ« hapura nÃ« kÃ«tÃ« domain
                sources = await self._crawl_domain_for_data(domain)
                discovered_sources.extend(sources)

                # Verifikon Ã§do burim
                for source in sources:
                    if await self._verify_data_source(source):
                        self.sources[source.id] = source
                        self.metrics.total_sources_discovered += 1

            except Exception as e:
                logger.error(f"Gabim gjatÃ« zbulimit tÃ« {domain}: {e}")

        # Ruaj burimet e reja
        await self._save_sources_to_disk()

        logger.info(f"ğŸ” Zbuluar {len(discovered_sources)} burime tÃ« reja")
        return discovered_sources

    async def _crawl_domain_for_data(self, domain: str) -> List[OpenDataSource]:
        """KÃ«rkon pÃ«r burime tÃ« dhÃ«nash nÃ« njÃ« domain"""
        sources = []

        # KÃ«rkon pÃ«r faqe tÃ« njohura tÃ« tÃ« dhÃ«nave
        data_pages = [
            f"https://data.{domain.replace('.', '')}.org",
            f"https://opendata.{domain.replace('.', '')}.org",
            f"https://research.{domain.replace('.', '')}.org/data",
            f"https://{domain.replace('.', '')}.edu/data",
            f"https://www.{domain.replace('.', '')}/open-data",
        ]

        for page_url in data_pages:
            try:
                async with self.session.get(page_url) as response:
                    if response.status == 200:
                        html = await response.text()
                        page_sources = self._extract_data_links_from_html(html, page_url)
                        sources.extend(page_sources)

            except Exception as e:
                logger.debug(f"Nuk mund tÃ« aksesohet {page_url}: {e}")

        return sources

    def _extract_data_links_from_html(self, html: str, base_url: str) -> List[OpenDataSource]:
        """Ekstrakton lidhje tÃ« tÃ« dhÃ«nave nga HTML"""
        sources = []

        # Regex pÃ«r lidhje API dhe tÃ« dhÃ«na
        patterns = [
            r'href=["\']([^"\']*\.(?:json|xml|csv|api|data)[^"\']*)["\']',
            r'src=["\']([^"\']*\.(?:json|xml|csv|api|data)[^"\']*)["\']',
            r'["\']([^"\']*api[^"\']*)["\']',
            r'["\']([^"\']*data[^"\']*\.(?:json|xml|csv)[^"\']*)["\']',
        ]

        for pattern in patterns:
            matches = re.findall(pattern, html, re.IGNORECASE)
            for match in matches:
                try:
                    full_url = urllib.parse.urljoin(base_url, match)
                    if self._is_valid_data_url(full_url):
                        source = OpenDataSource(
                            url=full_url,
                            name=f"Auto-discovered from {base_url}",
                            source_type=self._guess_source_type(full_url)
                        )
                        sources.append(source)
                except:
                    continue

        return sources

    def _is_valid_data_url(self, url: str) -> bool:
        """Verifikon nÃ«se URL Ã«shtÃ« njÃ« burim i vlefshÃ«m i tÃ« dhÃ«nave"""
        if not url or len(url) < 10:
            return False

        # Kontrollon pÃ«r ekstensione tÃ« tÃ« dhÃ«nave
        data_extensions = ['.json', '.xml', '.csv', '.api', '/api/', '/data/']
        if any(ext in url.lower() for ext in data_extensions):
            return True

        # Kontrollon pÃ«r domain-e tÃ« njohura
        trusted_domains = ['.edu', '.gov', '.org', '.ac.', 'cern.ch', 'nasa.gov']
        if any(domain in url.lower() for domain in trusted_domains):
            return True

        return False

    def _guess_source_type(self, url: str) -> DataSourceType:
        """Gjen llojin e burimit nga URL"""
        url_lower = url.lower()

        if any(term in url_lower for term in ['pubmed', 'nih', 'clinical', 'medical']):
            return DataSourceType.HEALTH
        elif any(term in url_lower for term in ['cern', 'nasa', 'research', 'science']):
            return DataSourceType.RESEARCH
        elif any(term in url_lower for term in ['edu', 'university', 'academic']):
            return DataSourceType.ACADEMIC
        elif any(term in url_lower for term in ['gov', 'government', 'state']):
            return DataSourceType.GOVERNMENT
        elif any(term in url_lower for term in ['environment', 'climate', 'weather']):
            return DataSourceType.ENVIRONMENTAL
        else:
            return DataSourceType.OPEN_DATA

    async def _verify_data_source(self, source: OpenDataSource) -> bool:
        """Verifikon njÃ« burim tÃ« tÃ« dhÃ«nave"""
        try:
            async with self.session.get(source.url, timeout=10) as response:
                if response.status == 200:
                    content_type = response.headers.get('content-type', '').lower()

                    # Kontrollon pÃ«r lloje tÃ« pÃ«rmbajtjes sÃ« tÃ« dhÃ«nave
                    if any(ct in content_type for ct in ['json', 'xml', 'csv', 'api']):
                        source.quality_score = DataQuality.GOOD
                        source.last_verified = datetime.now(timezone.utc)
                        return True

                    # Kontrollon pÃ«r robots.txt pÃ«r respektim
                    robots_url = urllib.parse.urljoin(source.url, '/robots.txt')
                    try:
                        async with self.session.get(robots_url) as robots_response:
                            if robots_response.status == 200:
                                robots_content = await robots_response.text()
                                if 'Disallow: /api' not in robots_content:
                                    source.quality_score = DataQuality.FAIR
                                    source.last_verified = datetime.now(timezone.utc)
                                    return True
                    except:
                        pass

        except Exception as e:
            logger.debug(f"Nuk mund tÃ« verifikohet {source.url}: {e}")

        return False

    async def feed_intelligent_modules(self, sources: List[OpenDataSource]) -> Dict[str, Any]:
        """
        Ushqen modulet inteligjente me tÃ« dhÃ«na dhe prodhon pÃ«rmbajtje tÃ« re

        Returns:
            Dictionary me rezultatet e prodhimit
        """
        results = {
            'api_alignments': [],
            'cycles_generated': [],
            'documentation': [],
            'simulations': [],
            'research_papers': [],
            'futuristic_concepts': []
        }

        for source in sources:
            if not source.active:
                continue

            try:
                # Merr tÃ« dhÃ«na nga burimi
                data = await self._ingest_data_from_source(source)

                if data:
                    # Gjeneron pÃ«rmbajtje tÃ« re
                    new_content = await self._generate_new_content_from_data(data, source)

                    # Shton rezultatet
                    for key, value in new_content.items():
                        if key in results:
                            results[key].extend(value)

                    # PÃ«rditÃ«son metrikat
                    self.metrics.data_ingested_gb += len(str(data)) / (1024**3)
                    self.metrics.active_sources += 1

            except Exception as e:
                logger.error(f"Gabim gjatÃ« pÃ«rpunimit tÃ« {source.url}: {e}")

        # Kontrolli i sigurisÃ« me JONA
        if self.jona:
            safe_results = await self._jona_safety_review(results)
            results.update(safe_results)

        return results

    async def _ingest_data_from_source(self, source: OpenDataSource) -> Optional[Any]:
        """Ingeston tÃ« dhÃ«na nga njÃ« burim"""
        try:
            async with self.session.get(source.url) as response:
                if response.status == 200:
                    content_type = response.headers.get('content-type', '')

                    if 'json' in content_type:
                        return await response.json()
                    elif 'xml' in content_type:
                        text = await response.text()
                        # Kthehet nÃ« dictionary tÃ« thjeshtÃ«
                        return {'xml_content': text, 'source': source.url}
                    elif 'csv' in content_type:
                        text = await response.text()
                        return {'csv_content': text, 'source': source.url}
                    else:
                        text = await response.text()
                        return {'text_content': text, 'source': source.url}

        except Exception as e:
            logger.error(f"Gabim gjatÃ« ingestimit nga {source.url}: {e}")

        return None

    async def _generate_new_content_from_data(self, data: Any, source: OpenDataSource) -> Dict[str, List[Any]]:
        """
        Gjeneron pÃ«rmbajtje tÃ« re nga tÃ« dhÃ«nat

        Kjo Ã«shtÃ« ku ndodh magjia - kombinimi i tÃ« dhÃ«nave reale me inteligjencÃ«
        pÃ«r tÃ« prodhuar kÃ«rkime dhe koncepte tÃ« reja.
        """
        content = {
            'api_alignments': [],
            'cycles_generated': [],
            'documentation': [],
            'simulations': [],
            'research_papers': [],
            'futuristic_concepts': []
        }

        # Analizon tÃ« dhÃ«nat pÃ«r modele dhe insights
        insights = await self._analyze_data_patterns(data, source)

        # Gjeneron API alignments bazuar nÃ« tÃ« dhÃ«na
        api_alignment = await self._generate_api_alignment(insights, source)
        if api_alignment:
            content['api_alignments'].append(api_alignment)

        # Krijon cycles tÃ« reja pÃ«r kÃ«tÃ« burim
        cycle = await self._generate_data_cycle(source, insights)
        if cycle:
            content['cycles_generated'].append(cycle)

        # Gjeneron dokumentacion
        docs = await self._generate_documentation(insights, source)
        content['documentation'].extend(docs)

        # Krijon simulime
        simulations = await self._generate_simulations(data, insights)
        content['simulations'].extend(simulations)

        # Gjeneron kÃ«rkime tÃ« reja
        research = await self._generate_research_papers(insights, source)
        content['research_papers'].extend(research)

        # Koncepte futuristike
        concepts = await self._generate_futuristic_concepts(insights, source)
        content['futuristic_concepts'].extend(concepts)

        return content

    async def _analyze_data_patterns(self, data: Any, source: OpenDataSource) -> Dict[str, Any]:
        """Analizon modele nÃ« tÃ« dhÃ«na"""
        insights = {
            'data_type': type(data).__name__,
            'size': len(str(data)) if hasattr(data, '__len__') else 0,
            'patterns': [],
            'correlations': [],
            'anomalies': [],
            'predictions': []
        }

        # AnalizÃ« themelore e modeleve
        if isinstance(data, dict):
            insights['patterns'].append(f"Dictionary me {len(data)} keys")
            for key, value in data.items():
                if isinstance(value, (list, dict)):
                    insights['patterns'].append(f"Key '{key}' ka {len(value)} elementÃ«")

        elif isinstance(data, list):
            insights['patterns'].append(f"ListÃ« me {len(data)} elementÃ«")
            if len(data) > 0:
                sample = data[0]
                insights['patterns'].append(f"ElementÃ«t janÃ« tÃ« tipit {type(sample).__name__}")

        # Gjeneron correlations artificiale pÃ«r demonstrim
        insights['correlations'].append({
            'type': 'temporal',
            'description': f'Correlation ndÃ«rmjet {source.source_type.value} dhe kohÃ«s',
            'confidence': 0.85
        })

        return insights

    async def _generate_api_alignment(self, insights: Dict, source: OpenDataSource) -> Optional[Dict]:
        """Gjeneron API alignment pÃ«r kÃ«tÃ« burim"""
        return {
            'source_id': source.id,
            'source_url': source.url,
            'alignment_type': 'data_ingestion',
            'endpoints': [
                f'/api/v1/data/{source.source_type.value}/{source.id}',
                f'/api/v1/insights/{source.source_type.value}/{source.id}'
            ],
            'data_format': 'json',
            'authentication': 'api_key',
            'rate_limit': '1000/hour',
            'generated_at': datetime.now(timezone.utc).isoformat()
        }

    async def _generate_data_cycle(self, source: OpenDataSource, insights: Dict) -> Optional[Dict]:
        """Gjeneron njÃ« cycle tÃ« ri pÃ«r kÃ«tÃ« burim tÃ« dhÃ«nash"""
        if not self.cycle_engine:
            return None

        cycle_def = CycleDefinition(
            domain=f"data_{source.source_type.value}",
            source=source.url,
            agent="SCALABILITY_ENGINE",
            task=f"ingest_{source.source_type.value}_data",
            cycle_type=CycleType.INTERVAL,
            interval=3600.0,  # Ã‡do orÃ«
            alignment=AlignmentPolicy.ETHICAL_GUARD,
            metadata={
                'data_source': source.id,
                'insights': insights,
                'generated_by': 'scalability_engine'
            }
        )

        # Krijon cycle nÃ« engine
        created_cycle = self.cycle_engine.create_cycle(
            domain=cycle_def.domain,
            source=cycle_def.source,
            agent=cycle_def.agent,
            task=cycle_def.task,
            cycle_type=cycle_def.cycle_type,
            interval=cycle_def.interval,
            alignment=cycle_def.alignment.value
        )

        self.metrics.cycles_generated += 1

        return {
            'cycle_id': created_cycle.cycle_id,
            'source': source.url,
            'task': cycle_def.task,
            'interval': cycle_def.interval
        }

    async def _generate_documentation(self, insights: Dict, source: OpenDataSource) -> List[Dict]:
        """Gjeneron dokumentacion pÃ«r tÃ« dhÃ«nat"""
        docs = []

        # Dokumentacion API
        api_doc = {
            'type': 'api_documentation',
            'title': f'API pÃ«r {source.name}',
            'content': f'# API Documentation for {source.name}\n\n'
                      f'Burimi: {source.url}\n'
                      f'Lloji: {source.source_type.value}\n\n'
                      f'## Insights\n'
                      f'- {len(insights.get("patterns", []))} modele tÃ« zbuluara\n'
                      f'- {len(insights.get("correlations", []))} correlations\n\n'
                      f'Generated by Scalability Engine at {datetime.now(timezone.utc).isoformat()}',
            'source_id': source.id
        }
        docs.append(api_doc)

        return docs

    async def _generate_simulations(self, data: Any, insights: Dict) -> List[Dict]:
        """Gjeneron simulime bazuar nÃ« tÃ« dhÃ«na"""
        simulations = []

        simulation = {
            'type': 'data_simulation',
            'title': f'Simulim pÃ«r {insights.get("data_type", "unknown")}',
            'parameters': {
                'data_size': insights.get('size', 0),
                'patterns': len(insights.get('patterns', [])),
                'confidence': 0.92
            },
            'results': {
                'predictions': insights.get('predictions', []),
                'scenarios': ['optimistic', 'pessimistic', 'realistic'],
                'accuracy': 0.89
            },
            'generated_at': datetime.now(timezone.utc).isoformat()
        }
        simulations.append(simulation)

        self.metrics.simulations_run += 1

        return simulations

    async def _generate_research_papers(self, insights: Dict, source: OpenDataSource) -> List[Dict]:
        """Gjeneron kÃ«rkime tÃ« reja nga insights"""
        papers = []

        paper = {
            'title': f'New Research: Patterns in {source.source_type.value.capitalize()} Data',
            'abstract': f'Ky kÃ«rkim analizon modele tÃ« reja tÃ« zbuluara nÃ« tÃ« dhÃ«nat '
                       f'nga {source.name}. PÃ«rmes analizÃ«s sÃ« avancuar, janÃ« identifikuar '
                       f'{len(insights.get("patterns", []))} modele dhe '
                       f'{len(insights.get("correlations", []))} correlations.',
            'keywords': ['data analysis', 'patterns', 'correlations', source.source_type.value],
            'methodology': 'Automated pattern recognition and correlation analysis',
            'findings': insights.get('patterns', []),
            'conclusions': 'TÃ« dhÃ«nat tregojnÃ« modele interesante qÃ« mund tÃ« Ã§ojnÃ« '
                          'nÃ« zbulime tÃ« reja nÃ« fushÃ«n e studiuar.',
            'source_id': source.id,
            'generated_at': datetime.now(timezone.utc).isoformat()
        }
        papers.append(paper)

        self.metrics.research_papers_generated += 1

        return papers

    async def _generate_futuristic_concepts(self, insights: Dict, source: OpenDataSource) -> List[Dict]:
        """Gjeneron koncepte futuristike nga tÃ« dhÃ«nat"""
        concepts = []

        concept = {
            'title': f'Futuristic Concept: AI-Enhanced {source.source_type.value.capitalize()} Intelligence',
            'description': f'NjÃ« sistem inteligjent qÃ« pÃ«rdor tÃ« dhÃ«nat nga {source.name} '
                          f'pÃ«r tÃ« parashikuar dhe optimizuar procese komplekse. '
                          f'Bazuar nÃ« {len(insights.get("patterns", []))} modele tÃ« zbuluara.',
            'applications': [
                'Predictive analytics for complex systems',
                'Automated optimization of processes',
                'Real-time decision support',
                'Futuristic human-AI collaboration'
            ],
            'ethical_considerations': [
                'Data privacy and security',
                'Bias mitigation in AI systems',
                'Human oversight and control',
                'Beneficial AI development'
            ],
            'timeline': '5-10 years for initial implementation',
            'impact': 'High - could revolutionize the field',
            'source_id': source.id,
            'generated_at': datetime.now(timezone.utc).isoformat()
        }
        concepts.append(concept)

        return concepts

    async def _jona_safety_review(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Kontrolli i sigurisÃ« me JONA"""
        if not self.jona:
            return {}

        safe_results = {}
        violations = 0

        for content_type, items in results.items():
            safe_items = []
            for item in items:
                # JONA kontrollon pÃ«r etikÃ« dhe siguri
                is_safe = await self._check_content_safety(item)

                if is_safe:
                    safe_items.append(item)
                else:
                    violations += 1
                    logger.warning(f"ğŸš« PÃ«rmbajtje e bllokuar nga JONA: {item.get('title', 'Unknown')}")

            safe_results[content_type] = safe_items

        self.metrics.safety_violations += violations
        self.metrics.jona_reviews += 1

        return safe_results

    async def _check_content_safety(self, content: Dict) -> bool:
        """Kontrollon sigurinÃ« e pÃ«rmbajtjes"""
        # Simulim i kontrollit tÃ« sigurisÃ«
        # NÃ« praktikÃ«, kjo do tÃ« integrohej me JONA

        # Kontrollon pÃ«r pÃ«rmbajtje problematike
        problematic_keywords = ['harmful', 'dangerous', 'illegal', 'unethical']

        content_str = json.dumps(content, default=str).lower()

        for keyword in problematic_keywords:
            if keyword in content_str:
                return False

        return True

    async def _load_sources_from_disk(self):
        """Ngarkon burimet nga disku"""
        try:
            sources_file = Path("data_sources.json")
            if sources_file.exists():
                with open(sources_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for source_data in data.get('sources', []):
                        source = OpenDataSource(**source_data)
                        self.sources[source.id] = source

                logger.info(f"Ngarkuar {len(self.sources)} burime nga disku")

        except Exception as e:
            logger.error(f"Gabim gjatÃ« ngarkimit tÃ« burimeve: {e}")

    async def _save_sources_to_disk(self):
        """Ruaj burimet nÃ« disk"""
        try:
            sources_file = Path("data_sources.json")
            sources_file.parent.mkdir(exist_ok=True)

            data = {
                'sources': [source.__dict__ for source in self.sources.values()],
                'last_updated': datetime.now(timezone.utc).isoformat(),
                'metrics': self.metrics.__dict__
            }

            with open(sources_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, default=str)

            logger.info(f"Ruajtur {len(self.sources)} burime nÃ« disk")

        except Exception as e:
            logger.error(f"Gabim gjatÃ« ruajtjes sÃ« burimeve: {e}")

    async def get_metrics(self) -> ScalabilityMetrics:
        """Merr metrikat aktuale"""
        return self.metrics

    async def shutdown(self):
        """Mbyll motorin"""
        if self.session:
            await self.session.close()

        self.executor.shutdown(wait=True)
        logger.info("ğŸ”Œ Open Data Scalability Engine u mbyll")

# Funksioni global pÃ«r inicializim
_scalability_engine: Optional[OpenDataScalabilityEngine] = None

async def get_scalability_engine(cycle_engine: Optional[Any] = None) -> OpenDataScalabilityEngine:
    """Merr instancÃ«n globale tÃ« motorit tÃ« skalabilitetit"""
    global _scalability_engine

    if _scalability_engine is None:
        _scalability_engine = OpenDataScalabilityEngine(cycle_engine)
        await _scalability_engine.initialize()

    return _scalability_engine

async def discover_and_feed_system():
    """
    Funksioni kryesor pÃ«r zbulim dhe ushqim tÃ« sistemit

    Ky funksion:
    1. Zbulon burime tÃ« reja tÃ« tÃ« dhÃ«nave
    2. I integrojnÃ« ato nÃ« sistem
    3. Ushqen tÃ« gjithÃ« modulet inteligjente
    4. ProdhojnÃ« pÃ«rmbajtje tÃ« re
    """
    try:
        # Inicializon motorin
        engine = await get_scalability_engine()

        logger.info("ğŸ” Filloj zbulimin e burimeve tÃ« tÃ« dhÃ«nave...")

        # Zbulon burime tÃ« reja
        new_sources = await engine.discover_data_sources()

        if new_sources:
            logger.info(f"âœ… Zbuluar {len(new_sources)} burime tÃ« reja")

            # Ushqen sistemin me tÃ« dhÃ«na
            logger.info("ğŸš€ Ushqej sistemin inteligjent...")
            results = await engine.feed_intelligent_modules(new_sources)

            # Shfaq rezultatet
            logger.info("ğŸ“Š Rezultatet:")
            for content_type, items in results.items():
                logger.info(f"  {content_type}: {len(items)} elementÃ«")

            # Ruaj metrikat
            metrics = await engine.get_metrics()
            logger.info(f"ğŸ“ˆ Metrika: {metrics.total_sources_discovered} burime, "
                       f"{metrics.cycles_generated} cycles, "
                       f"{metrics.research_papers_generated} kÃ«rkime")

        else:
            logger.info("â„¹ï¸ Nuk u zbuluan burime tÃ« reja")

    except Exception as e:
        logger.error(f"Gabim nÃ« sistemin e skalabilitetit: {e}")
    finally:
        # Shutdown will be handled by the caller
        pass</content>
<parameter name="filePath">c:\Users\pc\Clisonix-cloud\open_data_scalability.py
