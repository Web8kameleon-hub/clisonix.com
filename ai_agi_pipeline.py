# -*- coding: utf-8 -*-
"""
ğŸ”§ AI/AGI PIPELINE MODULES
===========================
Module pÃ«r krijimin dhe menaxhimin e pipeline-ve tÃ« inteligjencÃ«s artificiale

Ky modul pÃ«rfshin:
- AI Pipeline Builder
- AGI Processing Chains
- Intelligence Flow Management
- Cross-Module Integration
- Real-time Pipeline Monitoring
"""

from __future__ import annotations
import asyncio
import json
import uuid
import time
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Set, Tuple, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import logging
import hashlib
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

# Konfigurimi i logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    from enhanced_asi import get_enhanced_asi, IntelligenceType, IntelligenceUnit
    from cycle_engine import CycleEngine, CycleType, AlignmentPolicy
    from open_data_scalability import get_scalability_engine
    INTEGRATIONS_AVAILABLE = True
except ImportError:
    logger.warning("Disa integrime nuk janÃ« tÃ« disponueshme")
    INTEGRATIONS_AVAILABLE = False

class PipelineType(Enum):
    """Llojet e pipeline-ve"""
    AI_PROCESSING = "ai_processing"        # PÃ«rpunim AI standard
    AGI_DEVELOPMENT = "agi_development"    # Zhvillim AGI
    INTELLIGENCE_FUSION = "intelligence_fusion"  # Fuzion inteligjence
    REAL_TIME_ANALYSIS = "real_time_analysis"    # AnalizÃ« real-time
    BATCH_PROCESSING = "batch_processing"        # PÃ«rpunim nÃ« grupe
    ADAPTIVE_LEARNING = "adaptive_learning"      # MÃ«sim adaptiv

class ProcessingStage(Enum):
    """Fazat e pÃ«rpunimit"""
    INPUT_VALIDATION = "input_validation"
    PREPROCESSING = "preprocessing"
    AI_ANALYSIS = "ai_analysis"
    AGI_SYNTHESIS = "agi_synthesis"
    INTELLIGENCE_FUSION = "intelligence_fusion"
    OUTPUT_GENERATION = "output_generation"
    QUALITY_ASSURANCE = "quality_assurance"
    DEPLOYMENT = "deployment"

@dataclass
class PipelineComponent:
    """Komponent i pipeline-it"""
    id: str = field(default_factory=lambda: f"pc_{uuid.uuid4().hex[:10]}")
    name: str = ""
    component_type: str = ""
    function: Optional[Callable] = None
    config: Dict[str, Any] = field(default_factory=dict)
    input_types: List[str] = field(default_factory=list)
    output_types: List[str] = field(default_factory=list)
    processing_time: float = 0.0
    success_rate: float = 1.0
    active: bool = True

@dataclass
class PipelineFlow:
    """Rrjedha e tÃ« dhÃ«nave nÃ« pipeline"""
    id: str = field(default_factory=lambda: f"pf_{uuid.uuid4().hex[:10]}")
    from_component: str = ""
    to_component: str = ""
    data_transform: Optional[Callable] = None
    conditions: Dict[str, Any] = field(default_factory=dict)
    active: bool = True

@dataclass
class AIPipeline:
    """Pipeline i plotÃ« AI/AGI"""
    id: str = field(default_factory=lambda: f"ai_{uuid.uuid4().hex[:12]}")
    name: str = ""
    pipeline_type: PipelineType = PipelineType.AI_PROCESSING
    components: Dict[str, PipelineComponent] = field(default_factory=dict)
    flows: List[PipelineFlow] = field(default_factory=list)
    input_schema: Dict[str, Any] = field(default_factory=dict)
    output_schema: Dict[str, Any] = field(default_factory=dict)
    active: bool = True
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    metrics: Dict[str, Any] = field(default_factory=dict)

@dataclass
class PipelineExecution:
    """Ekzekutim i pipeline-it"""
    id: str = field(default_factory=lambda: f"pe_{uuid.uuid4().hex[:12]}")
    pipeline_id: str = ""
    input_data: Any = None
    current_stage: ProcessingStage = ProcessingStage.INPUT_VALIDATION
    results: Dict[str, Any] = field(default_factory=dict)
    errors: List[str] = field(default_factory=list)
    started_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    completed_at: Optional[datetime] = None
    success: bool = False
    performance_metrics: Dict[str, Any] = field(default_factory=dict)

class AIPipelineBuilder:
    """
    Builder pÃ«r pipeline AI/AGI

    Krijon dhe konfiguron pipeline tÃ« sofistikuar pÃ«r pÃ«rpunim inteligjent.
    """

    def __init__(self):
        self.pipelines: Dict[str, AIPipeline] = {}
        self.executions: Dict[str, PipelineExecution] = {}
        self.component_library: Dict[str, PipelineComponent] = {}

        # Inicializo librarinÃ« e komponenteve
        self._initialize_component_library()

        logger.info("ğŸ”§ AI Pipeline Builder inicializuar")

    def _initialize_component_library(self):
        """Inicializon librarinÃ« e komponenteve standarde"""

        # Komponent AI themelor
        self.component_library['data_ingestor'] = PipelineComponent(
            name="Data Ingestor",
            component_type="input",
            input_types=["raw_data"],
            output_types=["structured_data"],
            config={"validate_input": True, "normalize": True}
        )

        self.component_library['ai_analyzer'] = PipelineComponent(
            name="AI Analyzer",
            component_type="processing",
            input_types=["structured_data"],
            output_types=["analysis_results"],
            config={"model_type": "transformer", "confidence_threshold": 0.7}
        )

        self.component_library['agi_synthesizer'] = PipelineComponent(
            name="AGI Synthesizer",
            component_type="synthesis",
            input_types=["analysis_results", "intelligence_units"],
            output_types=["synthetic_intelligence"],
            config={"fusion_method": "neural_fusion", "ethical_check": True}
        )

        self.component_library['intelligence_fuser'] = PipelineComponent(
            name="Intelligence Fuser",
            component_type="fusion",
            input_types=["synthetic_intelligence", "external_knowledge"],
            output_types=["fused_intelligence"],
            config={"fusion_weight": 0.5, "conflict_resolution": "consensus"}
        )

        self.component_library['output_generator'] = PipelineComponent(
            name="Output Generator",
            component_type="output",
            input_types=["fused_intelligence"],
            output_types=["final_output"],
            config={"format": "json", "include_metadata": True}
        )

        self.component_library['quality_checker'] = PipelineComponent(
            name="Quality Checker",
            component_type="validation",
            input_types=["final_output"],
            output_types=["validated_output"],
            config={"quality_threshold": 0.8, "ethical_review": True}
        )

    def create_pipeline(self, name: str, pipeline_type: PipelineType = PipelineType.AI_PROCESSING) -> AIPipeline:
        """
        Krijon njÃ« pipeline tÃ« ri

        Args:
            name: Emri i pipeline-it
            pipeline_type: Lloji i pipeline-it
        """
        pipeline = AIPipeline(
            name=name,
            pipeline_type=pipeline_type
        )

        # Shto komponentet bazÃ« sipas llojit
        if pipeline_type == PipelineType.AI_PROCESSING:
            self._add_ai_processing_components(pipeline)
        elif pipeline_type == PipelineType.AGI_DEVELOPMENT:
            self._add_agi_development_components(pipeline)
        elif pipeline_type == PipelineType.INTELLIGENCE_FUSION:
            self._add_intelligence_fusion_components(pipeline)

        self.pipelines[pipeline.id] = pipeline
        logger.info(f"âœ… Krijuar pipeline: {name} ({pipeline_type.value})")
        return pipeline

    def _add_ai_processing_components(self, pipeline: AIPipeline):
        """Shton komponentet pÃ«r pÃ«rpunim AI"""
        components = ['data_ingestor', 'ai_analyzer', 'output_generator', 'quality_checker']

        for comp_name in components:
            if comp_name in self.component_library:
                comp = self.component_library[comp_name]
                pipeline.components[comp.id] = comp

        # Krijon rrjedhat
        self._create_linear_flow(pipeline, components)

    def _add_agi_development_components(self, pipeline: AIPipeline):
        """Shton komponentet pÃ«r zhvillim AGI"""
        components = ['data_ingestor', 'ai_analyzer', 'agi_synthesizer', 'intelligence_fuser', 'output_generator', 'quality_checker']

        for comp_name in components:
            if comp_name in self.component_library:
                comp = self.component_library[comp_name]
                pipeline.components[comp.id] = comp

        # Krijon rrjedhat me degÃ«zim
        self._create_agi_flow(pipeline, components)

    def _add_intelligence_fusion_components(self, pipeline: AIPipeline):
        """Shton komponentet pÃ«r fuzion inteligjence"""
        components = ['data_ingestor', 'intelligence_fuser', 'agi_synthesizer', 'output_generator', 'quality_checker']

        for comp_name in components:
            if comp_name in self.component_library:
                comp = self.component_library[comp_name]
                pipeline.components[comp.id] = comp

        # Krijon rrjedhat paralele
        self._create_fusion_flow(pipeline, components)

    def _create_linear_flow(self, pipeline: AIPipeline, component_names: List[str]):
        """Krijon rrjedhÃ« lineare"""
        for i in range(len(component_names) - 1):
            from_comp = component_names[i]
            to_comp = component_names[i + 1]

            flow = PipelineFlow(
                from_component=from_comp,
                to_component=to_comp
            )
            pipeline.flows.append(flow)

    def _create_agi_flow(self, pipeline: AIPipeline, component_names: List[str]):
        """Krijon rrjedhÃ« pÃ«r AGI me degÃ«zim"""
        # RrjedhÃ« themelore
        self._create_linear_flow(pipeline, component_names[:3])

        # DegÃ«zim pÃ«r sintetizim
        flow1 = PipelineFlow(
            from_component='ai_analyzer',
            to_component='agi_synthesizer',
            conditions={'high_confidence': True}
        )
        pipeline.flows.append(flow1)

        # Vazhdim i rrjedhÃ«s
        self._create_linear_flow(pipeline, component_names[3:])

    def _create_fusion_flow(self, pipeline: AIPipeline, component_names: List[str]):
        """Krijon rrjedhÃ« paralele pÃ«r fuzion"""
        # RrjedhÃ« paralele nga ingestori
        for comp_name in component_names[1:]:
            flow = PipelineFlow(
                from_component='data_ingestor',
                to_component=comp_name
            )
            pipeline.flows.append(flow)

        # Konvergim nÃ« output
        for comp_name in component_names[1:-1]:
            flow = PipelineFlow(
                from_component=comp_name,
                to_component='output_generator'
            )
            pipeline.flows.append(flow)

    def add_custom_component(self, pipeline_id: str, component: PipelineComponent):
        """Shton njÃ« komponent tÃ« personalizuar nÃ« pipeline"""
        if pipeline_id not in self.pipelines:
            raise ValueError(f"Pipeline {pipeline_id} nuk ekziston")

        pipeline = self.pipelines[pipeline_id]
        pipeline.components[component.id] = component

        logger.info(f"â• Shtuar komponent: {component.name} nÃ« pipeline {pipeline.name}")

    async def execute_pipeline(self, pipeline_id: str, input_data: Any) -> PipelineExecution:
        """
        Ekzekuton njÃ« pipeline me tÃ« dhÃ«na input

        Args:
            pipeline_id: ID e pipeline-it
            input_data: TÃ« dhÃ«nat pÃ«r pÃ«rpunim
        """
        if pipeline_id not in self.pipelines:
            raise ValueError(f"Pipeline {pipeline_id} nuk ekziston")

        pipeline = self.pipelines[pipeline_id]

        # Krijon ekzekutim
        execution = PipelineExecution(
            pipeline_id=pipeline_id,
            input_data=input_data
        )

        self.executions[execution.id] = execution

        try:
            # Ekzekuto Ã§do fazÃ«
            for stage in ProcessingStage:
                execution.current_stage = stage
                result = await self._execute_stage(pipeline, execution, stage)

                if result.get('error'):
                    execution.errors.append(result['error'])
                    break

                execution.results[stage.value] = result

            execution.success = len(execution.errors) == 0
            execution.completed_at = datetime.now(timezone.utc)

            # PÃ«rditÃ«so metrikat e pipeline-it
            self._update_pipeline_metrics(pipeline, execution)

        except Exception as e:
            execution.errors.append(str(e))
            execution.success = False
            logger.error(f"âŒ Gabim nÃ« ekzekutimin e pipeline-it {pipeline_id}: {e}")

        return execution

    async def _execute_stage(self, pipeline: AIPipeline, execution: PipelineExecution, stage: ProcessingStage) -> Dict[str, Any]:
        """Ekzekuton njÃ« fazÃ« specifike"""
        start_time = time.time()

        try:
            if stage == ProcessingStage.INPUT_VALIDATION:
                result = await self._validate_input(execution.input_data, pipeline)

            elif stage == ProcessingStage.PREPROCESSING:
                result = await self._preprocess_data(execution.input_data)

            elif stage == ProcessingStage.AI_ANALYSIS:
                result = await self._perform_ai_analysis(execution.input_data)

            elif stage == ProcessingStage.AGI_SYNTHESIS:
                result = await self._perform_agi_synthesis(execution.results)

            elif stage == ProcessingStage.INTELLIGENCE_FUSION:
                result = await self._perform_intelligence_fusion(execution.results)

            elif stage == ProcessingStage.OUTPUT_GENERATION:
                result = await self._generate_output(execution.results, pipeline)

            elif stage == ProcessingStage.QUALITY_ASSURANCE:
                result = await self._perform_quality_assurance(execution.results)

            elif stage == ProcessingStage.DEPLOYMENT:
                result = await self._deploy_results(execution.results)

            else:
                result = {'status': 'skipped', 'message': f'Faza {stage.value} nuk Ã«shtÃ« implementuar'}

            # Shto metrikat e performancÃ«s
            processing_time = time.time() - start_time
            result['processing_time'] = processing_time
            result['stage'] = stage.value

            return result

        except Exception as e:
            return {
                'error': str(e),
                'stage': stage.value,
                'processing_time': time.time() - start_time
            }

    async def _validate_input(self, input_data: Any, pipeline: AIPipeline) -> Dict[str, Any]:
        """Validon tÃ« dhÃ«nat input"""
        result = {'valid': True, 'issues': []}

        # Kontrollo skemÃ«n
        if pipeline.input_schema:
            # Simulim validimi
            if not isinstance(input_data, dict):
                result['valid'] = False
                result['issues'].append("Input duhet tÃ« jetÃ« dictionary")

        # Kontrollo pÃ«r tÃ« dhÃ«na problematike
        if input_data is None:
            result['valid'] = False
            result['issues'].append("Input Ã«shtÃ« null")

        return result

    async def _preprocess_data(self, data: Any) -> Dict[str, Any]:
        """PÃ«rpunon paraprakisht tÃ« dhÃ«nat"""
        result = {'processed_data': data, 'transformations': []}

        if isinstance(data, str):
            # Normalizim teksti
            result['processed_data'] = data.lower().strip()
            result['transformations'].append('text_normalization')

        elif isinstance(data, dict):
            # Strukturim i tÃ« dhÃ«nave
            result['processed_data'] = {k.lower(): v for k, v in data.items()}
            result['transformations'].append('key_normalization')

        return result

    async def _perform_ai_analysis(self, data: Any) -> Dict[str, Any]:
        """Kryen analizÃ« AI"""
        result = {
            'insights': [],
            'confidence': 0.8,
            'patterns': [],
            'recommendations': []
        }

        # Simulim analizÃ« AI
        if isinstance(data, str) and len(data) > 10:
            result['insights'].append("Teksti pÃ«rmban informacion tÃ« vlefshÃ«m")
            result['patterns'].append("text_pattern_detected")

        elif isinstance(data, dict):
            result['insights'].append(f"Dictionary me {len(data)} fusha")
            result['patterns'].append("structured_data_pattern")

        return result

    async def _perform_agi_synthesis(self, previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """Kryen sintetizim AGI"""
        result = {
            'synthetic_intelligence': [],
            'new_concepts': [],
            'intelligence_gain': 0.0
        }

        # Merr rezultatet e mÃ«parshme
        ai_analysis = previous_results.get('ai_analysis', {})

        # Gjeneron inteligjencÃ« sintetike
        if ai_analysis.get('insights'):
            synthetic_concept = {
                'type': 'emergent_intelligence',
                'description': 'InteligjencÃ« e re nga kombinimi i tÃ« dhÃ«nave',
                'confidence': 0.85
            }
            result['synthetic_intelligence'].append(synthetic_concept)
            result['intelligence_gain'] = 0.15

        return result

    async def _perform_intelligence_fusion(self, previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """Kryen fuzion inteligjence"""
        result = {
            'fused_intelligence': {},
            'fusion_strength': 0.0,
            'conflicts_resolved': 0
        }

        # Kombinon rezultatet nga fazat e ndryshme
        all_results = []
        for stage_result in previous_results.values():
            if isinstance(stage_result, dict) and 'insights' in stage_result:
                all_results.extend(stage_result['insights'])

        if all_results:
            result['fused_intelligence'] = {
                'combined_insights': all_results,
                'fusion_timestamp': datetime.now(timezone.utc).isoformat()
            }
            result['fusion_strength'] = min(1.0, len(all_results) * 0.1)

        return result

    async def _generate_output(self, results: Dict[str, Any], pipeline: AIPipeline) -> Dict[str, Any]:
        """Gjeneron output final"""
        output = {
            'pipeline_id': pipeline.id,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'results': {},
            'metadata': {
                'execution_time': 'calculated',
                'quality_score': 0.85
            }
        }

        # Kombinon rezultatet
        for stage, stage_result in results.items():
            if isinstance(stage_result, dict) and 'error' not in stage_result:
                output['results'][stage] = stage_result

        return output

    async def _perform_quality_assurance(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Kryen kontroll cilÃ«sie"""
        qa_result = {
            'quality_score': 0.8,
            'issues': [],
            'recommendations': []
        }

        # Kontrollo pÃ«r gabime
        error_count = sum(1 for r in results.values() if isinstance(r, dict) and 'error' in r)
        if error_count > 0:
            qa_result['issues'].append(f"GjetÃ«n {error_count} gabime")
            qa_result['quality_score'] -= error_count * 0.1

        # Kontrollo pÃ«r rezultate boshe
        empty_results = sum(1 for r in results.values() if isinstance(r, dict) and not r)
        if empty_results > 0:
            qa_result['issues'].append(f"{empty_results} rezultate boshe")
            qa_result['quality_score'] -= empty_results * 0.05

        return qa_result

    async def _deploy_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Implementon rezultatet"""
        deployment = {
            'deployed': True,
            'target_systems': [],
            'deployment_id': f"dep_{uuid.uuid4().hex[:8]}",
            'timestamp': datetime.now(timezone.utc).isoformat()
        }

        # Integrime me sisteme tÃ« tjera
        if INTEGRATIONS_AVAILABLE:
            try:
                # Dergo nÃ« Enhanced ASI
                asi = await get_enhanced_asi()
                deployment['target_systems'].append('enhanced_asi')

                # Dergo nÃ« Scalability Engine
                scalability = await get_scalability_engine()
                deployment['target_systems'].append('scalability_engine')

            except Exception as e:
                logger.warning(f"Gabim nÃ« deployment: {e}")

        return deployment

    def _update_pipeline_metrics(self, pipeline: AIPipeline, execution: PipelineExecution):
        """PÃ«rditÃ«son metrikat e pipeline-it"""
        if 'executions' not in pipeline.metrics:
            pipeline.metrics['executions'] = 0
        if 'success_rate' not in pipeline.metrics:
            pipeline.metrics['success_rate'] = 1.0
        if 'avg_processing_time' not in pipeline.metrics:
            pipeline.metrics['avg_processing_time'] = 0.0

        pipeline.metrics['executions'] += 1

        # Llogarit kohÃ«n totale tÃ« pÃ«rpunimit
        total_time = sum(r.get('processing_time', 0) for r in execution.results.values()
                        if isinstance(r, dict))

        # PÃ«rditÃ«so kohÃ«n mesatare
        current_avg = pipeline.metrics['avg_processing_time']
        executions = pipeline.metrics['executions']
        pipeline.metrics['avg_processing_time'] = (current_avg * (executions - 1) + total_time) / executions

        # PÃ«rditÃ«so shkallÃ«n e suksesit
        if execution.success:
            success_rate = (pipeline.metrics['success_rate'] * (executions - 1) + 1) / executions
        else:
            success_rate = (pipeline.metrics['success_rate'] * (executions - 1)) / executions

        pipeline.metrics['success_rate'] = success_rate

    def get_pipeline_metrics(self, pipeline_id: str) -> Dict[str, Any]:
        """Merr metrikat e njÃ« pipeline-i"""
        if pipeline_id not in self.pipelines:
            return {}

        pipeline = self.pipelines[pipeline_id]
        return {
            'pipeline_id': pipeline_id,
            'name': pipeline.name,
            'type': pipeline.pipeline_type.value,
            'active_components': len([c for c in pipeline.components.values() if c.active]),
            'total_components': len(pipeline.components),
            'flows': len(pipeline.flows),
            **pipeline.metrics
        }

    async def create_adaptive_pipeline(self, domain: str, requirements: Dict[str, Any]) -> AIPipeline:
        """
        Krijon njÃ« pipeline adaptiv bazuar nÃ« kÃ«rkesa

        Args:
            domain: Domain-i i aplikimit
            requirements: KÃ«rkesat specifike
        """
        # PÃ«rcakto llojin e pipeline-it
        pipeline_type = self._determine_pipeline_type(domain, requirements)

        # Krijon pipeline bazÃ«
        pipeline = self.create_pipeline(
            f"Adaptive Pipeline for {domain}",
            pipeline_type
        )

        # Shto komponentet adaptivÃ«
        adaptive_components = await self._generate_adaptive_components(domain, requirements)
        for component in adaptive_components:
            self.add_custom_component(pipeline.id, component)

        # Konfiguro rrjedhat adaptivÃ«
        await self._configure_adaptive_flows(pipeline, requirements)

        logger.info(f"ğŸ”„ Krijuar pipeline adaptiv pÃ«r {domain}")
        return pipeline

    def _determine_pipeline_type(self, domain: str, requirements: Dict[str, Any]) -> PipelineType:
        """PÃ«rcakton llojin e pipeline-it nga kÃ«rkesat"""
        if requirements.get('real_time', False):
            return PipelineType.REAL_TIME_ANALYSIS
        elif requirements.get('agi_focus', False):
            return PipelineType.AGI_DEVELOPMENT
        elif requirements.get('fusion_required', False):
            return PipelineType.INTELLIGENCE_FUSION
        elif requirements.get('batch_processing', False):
            return PipelineType.BATCH_PROCESSING
        else:
            return PipelineType.AI_PROCESSING

    async def _generate_adaptive_components(self, domain: str, requirements: Dict[str, Any]) -> List[PipelineComponent]:
        """Gjeneron komponentet adaptivÃ«"""
        components = []

        # Komponent pÃ«r domain specifik
        domain_component = PipelineComponent(
            name=f"{domain.capitalize()} Processor",
            component_type="domain_specific",
            input_types=["domain_data"],
            output_types=["processed_domain_data"],
            config={"domain": domain, **requirements}
        )
        components.append(domain_component)

        # Komponent pÃ«r kÃ«rkesa specifike
        if requirements.get('ethical_check', False):
            ethics_component = PipelineComponent(
                name="Ethics Validator",
                component_type="validation",
                input_types=["processed_data"],
                output_types=["ethical_data"],
                config={"strict_mode": requirements.get('strict_ethics', False)}
            )
            components.append(ethics_component)

        if requirements.get('quality_threshold', 0) > 0:
            quality_component = PipelineComponent(
                name="Quality Enhancer",
                component_type="enhancement",
                input_types=["processed_data"],
                output_types=["enhanced_data"],
                config={"threshold": requirements['quality_threshold']}
            )
            components.append(quality_component)

        return components

    async def _configure_adaptive_flows(self, pipeline: AIPipeline, requirements: Dict[str, Any]):
        """Konfiguro rrjedhat adaptivÃ«"""
        # Shto rrjedha bazuar nÃ« kÃ«rkesa
        if requirements.get('parallel_processing', False):
            # Krijon pÃ«rpunim paralel
            for component in pipeline.components.values():
                if component.component_type == 'domain_specific':
                    # Shto rrjedha paralele
                    parallel_flow = PipelineFlow(
                        from_component=list(pipeline.components.keys())[0],  # Nga input
                        to_component=component.id,
                        conditions={'parallel_mode': True}
                    )
                    pipeline.flows.append(parallel_flow)

# InstancÃ« globale
_pipeline_builder: Optional[AIPipelineBuilder] = None

async def get_pipeline_builder() -> AIPipelineBuilder:
    """Merr instancÃ«n globale tÃ« pipeline builder"""
    global _pipeline_builder

    if _pipeline_builder is None:
        _pipeline_builder = AIPipelineBuilder()

    return _pipeline_builder